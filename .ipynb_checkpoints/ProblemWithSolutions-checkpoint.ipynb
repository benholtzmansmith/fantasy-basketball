{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Problem: construct the best team from a list of available players. Best team is defined as the team that wins the most categories. Best team wins and all others lose (edit: make this function take the payout fractions as a parameter so it can adapt to different game types)\n",
    "\n",
    "Environment:\n",
    "(1) Player: a player represents an nba player with some total stats<br>\n",
    "(2) Team: a team has a list of current players and has a function for selecting another player\n",
    "(3) Scoring: \n",
    "    Idea 1 (Balanced): Each team competes over n categories. Teams are rated 1 - m representing who a sorted list of teams with lowest to highest scores in that category - m is the number of teams in the league. Score per team is = sum of individual score for each category. Teams are ranked at the end from highest to lowest score. Highest team wins. Downside: doesn't capture variance and distance between teams in individual categories. Doesn't capture winner takes all nature of problem.\n",
    "    Idea 2 (Extreme) : Each team competes over n categories. Best team gets a 1 for that category, all others get 0s. Score per team is = sum of individual score for each category. Teams are ranked at the end from highest to lowest score. Highest team wins.\n",
    "    Idea 3 (Distance): Each team competes over n categories. Teams get scored by calculating the zscore for each team to capture the size of the \"win\". An entire teams score is the sum of zscores. Or could take the zscore of the zscores for truly meta.\n",
    "\n",
    "Solutions:\n",
    "(1) Score players. Draft top remaining score.\n",
    "(2) Constraint solver: Run a search algo that computes every possible team and competitor team with the remaining players. Scores teams. Ranks teams. Takes player that produces the highest team score. Downside: going to take a long time to run. Needs to be able to run within 150s.\n",
    "(3) Monte carlo the problem. Predict performance for 2017. Run random simulations. If team wins, all players on winning team +1. Take make player with some random selection for exploration.\n",
    "(4) More sophistacted reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from abc import ABCMeta, abstractmethod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = []\n",
    "s.append('v')\n",
    "m = deepcopy(s)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player(object):\n",
    "    def __init__(self, name, stats):\n",
    "        self.name = name\n",
    "        self.stats = stats\n",
    "    \n",
    "class Stats(object):\n",
    "    def __init__(self, points, assists, rebounds):\n",
    "        self.points = points\n",
    "        self.assists = assists\n",
    "    #self.steals = 0\n",
    "    #self.tos = 0\n",
    "        self.rebounds = rebounds\n",
    "    #self.fgp = 0\n",
    "    #self.ftm = 0\n",
    "    #self.tpm = 0\n",
    "    #self.blocks = 0\n",
    "    #self.ftp = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draft(env, numberOfDraftRounds):\n",
    "    #Put something here so that you can't run draft with more rounds than available players\n",
    "    newEnv = env\n",
    "    for round in range(0, numberOfDraftRounds):\n",
    "        for agent in env.agents:\n",
    "            newEnv = agent.action(newEnv)\n",
    "    return newEnv\n",
    "\n",
    "#too much mutation, make more functional\n",
    "def draftOneRoundRandomly(env):\n",
    "    #Put something here so that you can't run draft with more rounds than available players\n",
    "    newEnv = env\n",
    "    newAgents = []\n",
    "    for agent in newEnv.agents:\n",
    "        envPlayers = newEnv.players\n",
    "        selected = envPlayers.pop(random.randint(0,len(envPlayers)-1))\n",
    "        newAgent = agent.copy()\n",
    "        newAgent.players.append(selected)\n",
    "        print(\"old players\", agent.players)\n",
    "        print(\"new players\", newAgent.players)\n",
    "        newAgents.append(newAgent)\n",
    "    return Environment(players = newEnv.players, agents = newAgents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    \n",
    "    __metaclass__ = ABCMeta\n",
    "    \n",
    "    @abstractmethod\n",
    "    def action(self, environment):\n",
    "        pass\n",
    "    \n",
    "    def copy(self):\n",
    "        pass\n",
    "\n",
    "class RandomAgent(Agent):\n",
    "    def __init__(self, players = []):\n",
    "        self.players = players\n",
    "        \n",
    "    def action(self, environment):\n",
    "        envPlayers = environment.players\n",
    "        selected = envPlayers.pop(random.randint(0,len(envPlayers)-1))\n",
    "        self.players.append(selected)\n",
    "        return Environment(players = envPlayers, agents = environment.agents)\n",
    "    \n",
    "    def copy(self):\n",
    "        players = deepcopy(self.players)\n",
    "        return RandomAgent(players)\n",
    "    \n",
    "class MaxPointsAgent(Agent):\n",
    "    def __init__(self, players = []):\n",
    "        self.players = players\n",
    "        \n",
    "    def action(self, environment):\n",
    "        envPlayers = environment.players\n",
    "        points_vec = [player.stats.points for player in players]\n",
    "        i = np.argmax(points_vec)\n",
    "        selected = envPlayers.pop(i)\n",
    "        self.players.append(selected)\n",
    "        return Environment(players = envPlayers, agents = environment.agents)\n",
    "    \n",
    "    def copy(self):\n",
    "        players = deepcopy(self.players)\n",
    "        return MaxPointsAgent(players)\n",
    "    \n",
    "class MonteCarloAgent(Agent):\n",
    "    def __init__(self, scorer, iters, players = []):\n",
    "        self.players = players\n",
    "        self.scorer = scorer\n",
    "        self.iters = iters\n",
    "            \n",
    "    def runSimulation(self, env):\n",
    "        newEnv = draftOneRoundRandomly(env)\n",
    "        return newEnv\n",
    "    \n",
    "    def action(self, environment):\n",
    "        experimental_environment = environment\n",
    "        player_tracker = {}\n",
    "        for i in range(0, self.iters):   \n",
    "            newEnv = self.runSimulation(experimental_environment)\n",
    "            winner_index = scorer.score(newEnv.agents)\n",
    "            winning_agent = agents[1]\n",
    "            if(winning_agent == self):\n",
    "                print(\"monte carlo won!\")\n",
    "                #Select the player that we just added -> we are going to keep track of those players and score them\n",
    "                new_players = [x for x in winning_agent.players if x not in self.players]\n",
    "                for player in new_players:\n",
    "                    player_tracker.update({player: int(player_tracker.get(player) or 0) + 1})\n",
    "        winning_player = player_tracker.keys()[np.argmax(player_tracker.values())]\n",
    "        self.players.append(winning_player)\n",
    "        envPlayers = environment.pop(environment.index(winning_player))\n",
    "        return Environment(players = envPlayers, agents = environment.agents)\n",
    "    \n",
    "    def copy(self):\n",
    "        players = deepcopy(self.players)\n",
    "        return MonteCarloAgent(scorer = self.scorer, iters = self.iters, players = players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scorer(object):\n",
    "    \n",
    "    __metaclass__ = ABCMeta\n",
    "    \n",
    "    @abstractmethod\n",
    "    def score(self, agents):\n",
    "        pass\n",
    "\n",
    "class SimpleSingleClassScorer(Scorer):\n",
    "    \"\"\"\n",
    "        Takes a list of agents. \n",
    "    \n",
    "        Scores by taking the argmax of a single category for those agents. \n",
    "        \n",
    "        Returns index of winner\n",
    "    \"\"\"\n",
    "    def score(self, agents):\n",
    "        list_of_points = []\n",
    "        for agent in agents:\n",
    "            players = agent.players\n",
    "            total_points = sum([player.stats.points for player in players])\n",
    "            list_of_points.append(total_points)\n",
    "        return np.argmax(list_of_points)\n",
    "    \n",
    "class SimpleMultiClassScorer(Scorer):\n",
    "    \"\"\"\n",
    "        Takes a list of agents. \n",
    "    \n",
    "        Scores by taking the argmax of a single category for those agents. \n",
    "        \n",
    "        Returns a vector in the order of the agents, representing\n",
    "        the commulative score of each agent\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.keys = ['points', 'assists']\n",
    "        \n",
    "    def score(self, agents):\n",
    "        list_of_points = []\n",
    "        list_of_assists = []\n",
    "        list_of_rebounds = []\n",
    "        score_dict = {}\n",
    "        for (i, agent) in enumerate(agents):\n",
    "            score_dict.update({i:0})\n",
    "            players = agent.players\n",
    "            total_points = sum([player.stats.points for player in players])\n",
    "            total_assists = sum([player.stats.assists for player in players])\n",
    "            total_rebounds = sum([player.stats.rebounds for player in players])\n",
    "            list_of_points.append(total_points)\n",
    "            list_of_assists.append(total_assists)\n",
    "            list_of_rebounds.append(total_rebounds)\n",
    "        index_points = np.argmax(list_of_points)\n",
    "        index_assists = np.argmax(list_of_assists)\n",
    "        index_rebounds = np.argmax(list_of_rebounds)\n",
    "        score_dict.update({index_points: int(score_dict.get(index_points) or 0) + 1})\n",
    "        score_dict.update({index_assists: int(score_dict.get(index_assists) or 0) + 1})\n",
    "        score_dict.update({index_rebounds: int(score_dict.get(index_rebounds) or 0) + 1})\n",
    "        i = np.argmax(score_dict.values())\n",
    "        return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, players, agents):\n",
    "        self.players = players\n",
    "        self.agents = agents\n",
    "        \n",
    "class Game(object):\n",
    "    def __init__(self, players, agents, scorer):\n",
    "        self.environment = Environment(players = players, agents = agents)\n",
    "        self.agents = agents\n",
    "        self.scorer = scorer\n",
    "        \n",
    "    def run(self, numberOfDraftRounds):\n",
    "        newEnv = draft(self.environment, numberOfDraftRounds)\n",
    "        finalAgents = newEnv.agents\n",
    "        i = scorer.score(finalAgents)\n",
    "        return (finalAgents[i], [player.name for player in finalAgents[i].players])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('old players', [<__main__.Player object at 0x1063bad10>])\n",
      "('new players', [<__main__.Player object at 0x1063b0050>, <__main__.Player object at 0x1063bacd0>])\n",
      "('old players', [])\n",
      "('new players', [<__main__.Player object at 0x1063bad90>])\n",
      "monte carlo won!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-80b6b4addd88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-7ea44e3d01fd>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, numberOfDraftRounds)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumberOfDraftRounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mnewEnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumberOfDraftRounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mfinalAgents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinalAgents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-44c086dc0421>\u001b[0m in \u001b[0;36mdraft\u001b[0;34m(env, numberOfDraftRounds)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mround\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumberOfDraftRounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mnewEnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnewEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-339e170aa259>\u001b[0m in \u001b[0;36maction\u001b[0;34m(self, environment)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mplayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_players\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0mplayer_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mwinning_player\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinning_player\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0menvPlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinning_player\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benjaminsmith/anaconda2/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \"\"\"\n\u001b[0;32m--> 963\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benjaminsmith/anaconda2/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# a downstream library like 'pandas'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benjaminsmith/anaconda2/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "p1 = Player(name = 'p1', stats = Stats(points = 10, assists = 7, rebounds = 15))\n",
    "p2 = Player(name = 'p2', stats = Stats(points = 3, assists = 4, rebounds = 7))\n",
    "p3 = Player(name = 'p3', stats = Stats(points = 15, assists = 10, rebounds = 20))\n",
    "p4 = Player(name = 'p4', stats = Stats(points = 10, assists = 7, rebounds = 15))\n",
    "p5 = Player(name = 'p5', stats = Stats(points = 3, assists = 4, rebounds = 7))\n",
    "p6 = Player(name = 'p6', stats = Stats(points = 15, assists = 10, rebounds = 20))\n",
    "\n",
    "scorer = SimpleMultiClassScorer()\n",
    "\n",
    "a1 = RandomAgent(players = [])\n",
    "#a2 = RandomAgent(players = [])\n",
    "a3 = MonteCarloAgent(scorer, 1, players = [])\n",
    "\n",
    "players = [p1,p2,p3, p4, p5, p6]\n",
    "agents = [a1, a3]\n",
    "\n",
    "game = Game(players = players, agents = agents, scorer = scorer)\n",
    "\n",
    "game.run(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScoreAndPick"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ScoreAndPick: this algo applies any scoring function to a set of players, sorts the players by their score and picks the top remaining player."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ComboSolver"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ComboSolver: this algo generates every possible team from the remaining players, scores the teams, and scores the players based on the team. This algo is adaptive and doesn't rely on pretraining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MonteCarloSortAndPick"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MontoCarloSortAndPick: Run random simulations. If team wins, all players on winning team +1. Take make player with some random selection for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
