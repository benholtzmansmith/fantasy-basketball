{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#What is the problem??\n",
    "#It dramatically depends on the kind of fantasy league you are playing\n",
    "#(1)Trying to predict which player combinations will win you the most number of points in any given week?\n",
    "#(2)Which players are going to be the best players next week/year/month?\n",
    "#One thing that is interesting is that best players probably, but might not, add up to the best teams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import keras\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#http://danielfrg.com/blog/2013/04/01/nba-scraping-data/\n",
    "url = 'http://espn.go.com/nba/teams'\n",
    "r = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(r.text)\n",
    "tables = soup.find_all('ul', class_='medium-logos')\n",
    "\n",
    "teams = []\n",
    "prefix_1 = []\n",
    "prefix_2 = []\n",
    "teams_urls = []\n",
    "for table in tables:\n",
    "    lis = table.find_all('li')\n",
    "    for li in lis:\n",
    "        info = li.h5.a\n",
    "        teams.append(info.text)\n",
    "        url = info['href']\n",
    "        teams_urls.append(url)\n",
    "        prefix_1.append(url.split('/')[-2])\n",
    "        prefix_2.append(url.split('/')[-1])\n",
    "\n",
    "\n",
    "dic = {'url': teams_urls, 'prefix_2': prefix_2, 'prefix_1': prefix_1}\n",
    "teams = pd.DataFrame(dic, index=teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix_1</th>\n",
       "      <th>prefix_2</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Boston Celtics</th>\n",
       "      <td>bos</td>\n",
       "      <td>boston-celtics</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/bos/boston...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brooklyn Nets</th>\n",
       "      <td>bkn</td>\n",
       "      <td>brooklyn-nets</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/bkn/brookl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York Knicks</th>\n",
       "      <td>ny</td>\n",
       "      <td>new-york-knicks</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/ny/new-yor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Philadelphia 76ers</th>\n",
       "      <td>phi</td>\n",
       "      <td>philadelphia-76ers</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/phi/philad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toronto Raptors</th>\n",
       "      <td>tor</td>\n",
       "      <td>toronto-raptors</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/tor/toront...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Golden State Warriors</th>\n",
       "      <td>gs</td>\n",
       "      <td>golden-state-warriors</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/gs/golden-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA Clippers</th>\n",
       "      <td>lac</td>\n",
       "      <td>la-clippers</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/lac/la-cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Angeles Lakers</th>\n",
       "      <td>lal</td>\n",
       "      <td>los-angeles-lakers</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/lal/los-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phoenix Suns</th>\n",
       "      <td>phx</td>\n",
       "      <td>phoenix-suns</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/phx/phoeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sacramento Kings</th>\n",
       "      <td>sac</td>\n",
       "      <td>sacramento-kings</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/sac/sacram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicago Bulls</th>\n",
       "      <td>chi</td>\n",
       "      <td>chicago-bulls</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/chi/chicag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cleveland Cavaliers</th>\n",
       "      <td>cle</td>\n",
       "      <td>cleveland-cavaliers</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/cle/clevel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detroit Pistons</th>\n",
       "      <td>det</td>\n",
       "      <td>detroit-pistons</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/det/detroi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana Pacers</th>\n",
       "      <td>ind</td>\n",
       "      <td>indiana-pacers</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/ind/indian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milwaukee Bucks</th>\n",
       "      <td>mil</td>\n",
       "      <td>milwaukee-bucks</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/mil/milwau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dallas Mavericks</th>\n",
       "      <td>dal</td>\n",
       "      <td>dallas-mavericks</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/dal/dallas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Rockets</th>\n",
       "      <td>hou</td>\n",
       "      <td>houston-rockets</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/hou/housto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Memphis Grizzlies</th>\n",
       "      <td>mem</td>\n",
       "      <td>memphis-grizzlies</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/mem/memphi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Orleans Pelicans</th>\n",
       "      <td>no</td>\n",
       "      <td>new-orleans-pelicans</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/no/new-orl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Antonio Spurs</th>\n",
       "      <td>sa</td>\n",
       "      <td>san-antonio-spurs</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/sa/san-ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atlanta Hawks</th>\n",
       "      <td>atl</td>\n",
       "      <td>atlanta-hawks</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/atl/atlant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charlotte Hornets</th>\n",
       "      <td>cha</td>\n",
       "      <td>charlotte-hornets</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/cha/charlo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miami Heat</th>\n",
       "      <td>mia</td>\n",
       "      <td>miami-heat</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/mia/miami-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orlando Magic</th>\n",
       "      <td>orl</td>\n",
       "      <td>orlando-magic</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/orl/orland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington Wizards</th>\n",
       "      <td>wsh</td>\n",
       "      <td>washington-wizards</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/wsh/washin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Denver Nuggets</th>\n",
       "      <td>den</td>\n",
       "      <td>denver-nuggets</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/den/denver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota Timberwolves</th>\n",
       "      <td>min</td>\n",
       "      <td>minnesota-timberwolves</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/min/minnes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma City Thunder</th>\n",
       "      <td>okc</td>\n",
       "      <td>oklahoma-city-thunder</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/okc/oklaho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portland Trail Blazers</th>\n",
       "      <td>por</td>\n",
       "      <td>portland-trail-blazers</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/por/portla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah Jazz</th>\n",
       "      <td>utah</td>\n",
       "      <td>utah-jazz</td>\n",
       "      <td>http://www.espn.com/nba/team/_/name/utah/utah-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       prefix_1                prefix_2  \\\n",
       "Boston Celtics              bos          boston-celtics   \n",
       "Brooklyn Nets               bkn           brooklyn-nets   \n",
       "New York Knicks              ny         new-york-knicks   \n",
       "Philadelphia 76ers          phi      philadelphia-76ers   \n",
       "Toronto Raptors             tor         toronto-raptors   \n",
       "Golden State Warriors        gs   golden-state-warriors   \n",
       "LA Clippers                 lac             la-clippers   \n",
       "Los Angeles Lakers          lal      los-angeles-lakers   \n",
       "Phoenix Suns                phx            phoenix-suns   \n",
       "Sacramento Kings            sac        sacramento-kings   \n",
       "Chicago Bulls               chi           chicago-bulls   \n",
       "Cleveland Cavaliers         cle     cleveland-cavaliers   \n",
       "Detroit Pistons             det         detroit-pistons   \n",
       "Indiana Pacers              ind          indiana-pacers   \n",
       "Milwaukee Bucks             mil         milwaukee-bucks   \n",
       "Dallas Mavericks            dal        dallas-mavericks   \n",
       "Houston Rockets             hou         houston-rockets   \n",
       "Memphis Grizzlies           mem       memphis-grizzlies   \n",
       "New Orleans Pelicans         no    new-orleans-pelicans   \n",
       "San Antonio Spurs            sa       san-antonio-spurs   \n",
       "Atlanta Hawks               atl           atlanta-hawks   \n",
       "Charlotte Hornets           cha       charlotte-hornets   \n",
       "Miami Heat                  mia              miami-heat   \n",
       "Orlando Magic               orl           orlando-magic   \n",
       "Washington Wizards          wsh      washington-wizards   \n",
       "Denver Nuggets              den          denver-nuggets   \n",
       "Minnesota Timberwolves      min  minnesota-timberwolves   \n",
       "Oklahoma City Thunder       okc   oklahoma-city-thunder   \n",
       "Portland Trail Blazers      por  portland-trail-blazers   \n",
       "Utah Jazz                  utah               utah-jazz   \n",
       "\n",
       "                                                                      url  \n",
       "Boston Celtics          http://www.espn.com/nba/team/_/name/bos/boston...  \n",
       "Brooklyn Nets           http://www.espn.com/nba/team/_/name/bkn/brookl...  \n",
       "New York Knicks         http://www.espn.com/nba/team/_/name/ny/new-yor...  \n",
       "Philadelphia 76ers      http://www.espn.com/nba/team/_/name/phi/philad...  \n",
       "Toronto Raptors         http://www.espn.com/nba/team/_/name/tor/toront...  \n",
       "Golden State Warriors   http://www.espn.com/nba/team/_/name/gs/golden-...  \n",
       "LA Clippers             http://www.espn.com/nba/team/_/name/lac/la-cli...  \n",
       "Los Angeles Lakers      http://www.espn.com/nba/team/_/name/lal/los-an...  \n",
       "Phoenix Suns            http://www.espn.com/nba/team/_/name/phx/phoeni...  \n",
       "Sacramento Kings        http://www.espn.com/nba/team/_/name/sac/sacram...  \n",
       "Chicago Bulls           http://www.espn.com/nba/team/_/name/chi/chicag...  \n",
       "Cleveland Cavaliers     http://www.espn.com/nba/team/_/name/cle/clevel...  \n",
       "Detroit Pistons         http://www.espn.com/nba/team/_/name/det/detroi...  \n",
       "Indiana Pacers          http://www.espn.com/nba/team/_/name/ind/indian...  \n",
       "Milwaukee Bucks         http://www.espn.com/nba/team/_/name/mil/milwau...  \n",
       "Dallas Mavericks        http://www.espn.com/nba/team/_/name/dal/dallas...  \n",
       "Houston Rockets         http://www.espn.com/nba/team/_/name/hou/housto...  \n",
       "Memphis Grizzlies       http://www.espn.com/nba/team/_/name/mem/memphi...  \n",
       "New Orleans Pelicans    http://www.espn.com/nba/team/_/name/no/new-orl...  \n",
       "San Antonio Spurs       http://www.espn.com/nba/team/_/name/sa/san-ant...  \n",
       "Atlanta Hawks           http://www.espn.com/nba/team/_/name/atl/atlant...  \n",
       "Charlotte Hornets       http://www.espn.com/nba/team/_/name/cha/charlo...  \n",
       "Miami Heat              http://www.espn.com/nba/team/_/name/mia/miami-...  \n",
       "Orlando Magic           http://www.espn.com/nba/team/_/name/orl/orland...  \n",
       "Washington Wizards      http://www.espn.com/nba/team/_/name/wsh/washin...  \n",
       "Denver Nuggets          http://www.espn.com/nba/team/_/name/den/denver...  \n",
       "Minnesota Timberwolves  http://www.espn.com/nba/team/_/name/min/minnes...  \n",
       "Oklahoma City Thunder   http://www.espn.com/nba/team/_/name/okc/oklaho...  \n",
       "Portland Trail Blazers  http://www.espn.com/nba/team/_/name/por/portla...  \n",
       "Utah Jazz               http://www.espn.com/nba/team/_/name/utah/utah-...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_prefixes_bbal_ref = ['BOS', 'BRK', 'NYK', 'PHI', 'TOR', 'GSW', 'LAC', 'LAL', 'PHO', 'SAC', \n",
    "                          'CHI', 'CLE', 'DET', 'IND', 'MIL', 'DAL', 'HOU', 'MEM','SAS', 'ATL','CHO', 'MIA',\n",
    "                         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BASE_URL_BBALL_REF = 'http://www.basketball-reference.com/teams/CLE/2017.html'\n",
    "r = requests.get(BASE_URL_BBALL_REF)\n",
    "table = BeautifulSoup(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'Dee Brown', u'26', u'79', u'69', u'2792', u'437', u'977', u'.447', u'126', u'327', u'.385', u'311', u'650', u'.478', u'.512', u'236', u'277', u'.852', u'63', u'186', u'249', u'301', u'110', u'49', u'146', u'181', u'1236'], [u'Dominique Wilkins', u'35', u'77', u'64', u'2423', u'496', u'1169', u'.424', u'112', u'289', u'.388', u'384', u'880', u'.436', u'.472', u'266', u'340', u'.782', u'157', u'244', u'401', u'166', u'61', u'14', u'173', u'130', u'1370'], [u'Eric Montross', u'23', u'78', u'75', u'2315', u'307', u'575', u'.534', u'0', u'1', u'.000', u'307', u'574', u'.535', u'.534', u'167', u'263', u'.635', u'196', u'370', u'566', u'36', u'29', u'61', u'112', u'299', u'781'], [u'Dino Radja', u'27', u'66', u'48', u'2147', u'450', u'919', u'.490', u'0', u'1', u'.000', u'450', u'918', u'.490', u'.490', u'233', u'307', u'.759', u'149', u'424', u'573', u'111', u'60', u'86', u'159', u'232', u'1133'], [u'Sherman Douglas', u'28', u'65', u'43', u'2048', u'365', u'769', u'.475', u'20', u'82', u'.244', u'345', u'687', u'.502', u'.488', u'204', u'296', u'.689', u'48', u'122', u'170', u'446', u'80', u'2', u'162', u'152', u'954'], [u'Xavier McDaniel', u'31', u'68', u'15', u'1430', u'246', u'546', u'.451', u'6', u'21', u'.286', u'240', u'525', u'.457', u'.456', u'89', u'125', u'.712', u'94', u'206', u'300', u'108', u'30', u'20', u'89', u'146', u'587'], [u'David Wesley', u'24', u'51', u'36', u'1380', u'128', u'313', u'.409', u'51', u'119', u'.429', u'77', u'194', u'.397', u'.490', u'71', u'94', u'.755', u'31', u'86', u'117', u'266', u'82', u'9', u'87', u'144', u'378'], [u'Derek Strong', u'26', u'70', u'24', u'1344', u'149', u'329', u'.453', u'2', u'7', u'.286', u'147', u'322', u'.457', u'.456', u'141', u'172', u'.820', u'136', u'239', u'375', u'44', u'24', u'13', u'79', u'143', u'441'], [u'Pervis Ellison', u'27', u'55', u'11', u'1083', u'152', u'300', u'.507', u'0', u'2', u'.000', u'152', u'298', u'.510', u'.507', u'71', u'99', u'.717', u'124', u'185', u'309', u'34', u'22', u'54', u'76', u'179', u'375'], [u'Rick Fox', u'25', u'53', u'7', u'1039', u'169', u'351', u'.481', u'31', u'75', u'.413', u'138', u'276', u'.500', u'.526', u'95', u'123', u'.772', u'61', u'94', u'155', u'139', u'52', u'19', u'78', u'154', u'464'], [u'Greg Minor', u'23', u'63', u'8', u'945', u'155', u'301', u'.515', u'2', u'12', u'.167', u'153', u'289', u'.529', u'.518', u'65', u'78', u'.833', u'49', u'88', u'137', u'66', u'32', u'16', u'44', u'89', u'377'], [u'Blue Edwards', u'29', u'31', u'7', u'507', u'83', u'195', u'.426', u'11', u'43', u'.256', u'72', u'152', u'.474', u'.454', u'43', u'48', u'.896', u'25', u'40', u'65', u'47', u'19', u'10', u'39', u'64', u'220'], [u'Acie Earl', u'24', u'30', u'3', u'208', u'26', u'68', u'.382', u'0', u'0', u'', u'26', u'68', u'.382', u'.382', u'14', u'29', u'.483', u'19', u'26', u'45', u'2', u'6', u'8', u'14', u'39', u'66'], [u'James Blackwell', u'26', u'9', u'0', u'61', u'6', u'10', u'.600', u'0', u'0', u'', u'6', u'10', u'.600', u'.600', u'2', u'3', u'.667', u'2', u'6', u'8', u'6', u'3', u'0', u'3', u'7', u'14'], [u'Jay Humphries', u'32', u'6', u'0', u'52', u'4', u'9', u'.444', u'0', u'1', u'.000', u'4', u'8', u'.500', u'.444', u'2', u'4', u'.500', u'2', u'1', u'3', u'10', u'2', u'0', u'5', u'10', u'10'], [u'Tony Harris', u'27', u'3', u'0', u'18', u'3', u'8', u'.375', u'0', u'1', u'.000', u'3', u'7', u'.429', u'.375', u'8', u'9', u'.889', u'0', u'0', u'0', u'0', u'0', u'0', u'1', u'2', u'14'], [u'Tony Dawson', u'27', u'2', u'0', u'13', u'3', u'8', u'.375', u'1', u'3', u'.333', u'2', u'5', u'.400', u'.438', u'1', u'1', u'1.000', u'0', u'3', u'3', u'1', u'0', u'0', u'2', u'4', u'8']]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-00a21f6e313e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"all_totals\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mformatted_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<!--\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"totals\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mplayer_data_per_team\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "BASE_URL_BBALL_REF = 'http://www.basketball-reference.com/teams/{0}/{1}.html'\n",
    "r = requests.get(BASE_URL_BBALL_REF)\n",
    "column_headers = [u'Name', u'Age', u'G', u'GS', u'MP', u'FG', u'FGA', u'FG%', u'3P', u'3PA', u'3P%', u'2P', u'2PA', u'2P%', u'eFG%', u'FT', u'FTA', u'FT%', u'ORB', u'DRB', u'TRB', u'AST', u'STL', u'BLK', u'TOV', u'PF', u'PTS']\n",
    "\n",
    "for year in range(1995, 2018):\n",
    "    player_data = []\n",
    "    for index, row in teams.iterrows():\n",
    "        r = requests.get(BASE_URL_BBALL_REF.format(row['prefix_1'].upper(), year))\n",
    "        html = str(BeautifulSoup(r.text).find(id=\"all_totals\"))\n",
    "        formatted_html = html.replace(\"<!--\", \"\")\n",
    "        table = BeautifulSoup(formatted_html).find(id=\"totals\").find_all('tr')\n",
    "        player_data_per_team = []\n",
    "        for row in table[1:]:\n",
    "            data = [td.getText() for td in row.findAll('td')]\n",
    "            player_data_per_team.append(data)\n",
    "        without_totals = player_data_per_team[:-1]\n",
    "        print(without_totals)\n",
    "        #formatted_data = [[data[0].encode('utf-8')] + [float(x) for x in data[1:]] for data in without_totals]\n",
    "        player_data.append(without_totals)\n",
    "    df = pd.DataFrame(player_data, columns=column_headers)\n",
    "    df.to_csv(\"player_stats_bball_ref\" + str(year) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>32.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>0.533</td>\n",
       "      <td>85.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691</td>\n",
       "      <td>61.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>24.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>0.466</td>\n",
       "      <td>113.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>36.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tristan Thompson</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1579.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513</td>\n",
       "      <td>193.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>28.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1466.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>119.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876</td>\n",
       "      <td>115.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iman Shumpert</td>\n",
       "      <td>26.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1246.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>0.428</td>\n",
       "      <td>70.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773</td>\n",
       "      <td>29.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Richard Jefferson</td>\n",
       "      <td>36.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.417</td>\n",
       "      <td>35.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735</td>\n",
       "      <td>19.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Channing Frye</td>\n",
       "      <td>33.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>0.443</td>\n",
       "      <td>89.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.826</td>\n",
       "      <td>26.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DeAndre Liggins</td>\n",
       "      <td>28.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.397</td>\n",
       "      <td>17.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677</td>\n",
       "      <td>12.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>J.R. Smith</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.337</td>\n",
       "      <td>50.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778</td>\n",
       "      <td>8.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kyle Korver</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.504</td>\n",
       "      <td>44.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jordan McRae</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.385</td>\n",
       "      <td>17.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794</td>\n",
       "      <td>6.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mike Dunleavy</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>20.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kay Felder</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.409</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>James Jones</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.536</td>\n",
       "      <td>24.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chris Andersen</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Derrick Williams</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name   Age     G    GS      MP     FG    FGA    FG%     3P  \\\n",
       "0        LeBron James  32.0  50.0  50.0  1880.0  481.0  903.0  0.533   85.0   \n",
       "1        Kyrie Irving  24.0  47.0  47.0  1653.0  427.0  917.0  0.466  113.0   \n",
       "2    Tristan Thompson  25.0  53.0  53.0  1579.0  171.0  293.0  0.584    0.0   \n",
       "3          Kevin Love  28.0  46.0  46.0  1466.0  292.0  681.0  0.429  119.0   \n",
       "4       Iman Shumpert  26.0  49.0  13.0  1246.0  131.0  306.0  0.428   70.0   \n",
       "5   Richard Jefferson  36.0  52.0   6.0  1022.0   93.0  223.0  0.417   35.0   \n",
       "6       Channing Frye  33.0  46.0   3.0   827.0  145.0  327.0  0.443   89.0   \n",
       "7     DeAndre Liggins  28.0  44.0  19.0   642.0   46.0  116.0  0.397   17.0   \n",
       "8          J.R. Smith  31.0  21.0  21.0   607.0   62.0  184.0  0.337   50.0   \n",
       "9         Kyle Korver  35.0  17.0   0.0   431.0   65.0  129.0  0.504   44.0   \n",
       "10       Jordan McRae  25.0  35.0   4.0   378.0   57.0  148.0  0.385   17.0   \n",
       "11      Mike Dunleavy  36.0  23.0   2.0   366.0   36.0   90.0  0.400   20.0   \n",
       "12         Kay Felder  21.0  34.0   0.0   339.0   54.0  132.0  0.409    7.0   \n",
       "13        James Jones  36.0  33.0   1.0   227.0   30.0   56.0  0.536   24.0   \n",
       "14     Chris Andersen  38.0  12.0   0.0   114.0    9.0   22.0  0.409    0.0   \n",
       "15   Derrick Williams  25.0   2.0   0.0    42.0    5.0    6.0  0.833    1.0   \n",
       "\n",
       "      3PA   ...      FT%    ORB    DRB    TRB    AST   STL   BLK    TOV  \\\n",
       "0   226.0   ...    0.691   61.0  328.0  389.0  440.0  73.0  29.0  212.0   \n",
       "1   286.0   ...    0.900   36.0  115.0  151.0  275.0  58.0  12.0  129.0   \n",
       "2     3.0   ...    0.513  193.0  318.0  511.0   44.0  30.0  62.0   41.0   \n",
       "3   310.0   ...    0.876  115.0  395.0  510.0   88.0  42.0  17.0   98.0   \n",
       "4   174.0   ...    0.773   29.0  120.0  149.0   76.0  49.0  15.0   49.0   \n",
       "5   119.0   ...    0.735   19.0  104.0  123.0   47.0  15.0   6.0   34.0   \n",
       "6   211.0   ...    0.826   26.0  136.0  162.0   29.0  18.0  22.0   32.0   \n",
       "7    44.0   ...    0.677   12.0   62.0   74.0   45.0  39.0  13.0   31.0   \n",
       "8   138.0   ...    0.778    8.0   37.0   45.0   26.0  26.0   9.0   15.0   \n",
       "9    88.0   ...    0.875    6.0   43.0   49.0   13.0   6.0   3.0   16.0   \n",
       "10   50.0   ...    0.794    6.0   34.0   40.0   18.0   8.0   6.0   14.0   \n",
       "11   57.0   ...    0.737    5.0   42.0   47.0   20.0   6.0   2.0   14.0   \n",
       "12   20.0   ...    0.711    3.0   32.0   35.0   47.0  13.0   6.0   23.0   \n",
       "13   41.0   ...    0.643    2.0   20.0   22.0    7.0   3.0   7.0    7.0   \n",
       "14    3.0   ...    0.714    9.0   22.0   31.0    5.0   5.0   7.0    5.0   \n",
       "15    2.0   ...    0.800    0.0    1.0    1.0    1.0   0.0   0.0    2.0   \n",
       "\n",
       "       PF     PTS  \n",
       "0    85.0  1289.0  \n",
       "1    99.0  1147.0  \n",
       "2   126.0   424.0  \n",
       "3    82.0   921.0  \n",
       "4    96.0   383.0  \n",
       "5    99.0   271.0  \n",
       "6    85.0   417.0  \n",
       "7    65.0   130.0  \n",
       "8    47.0   181.0  \n",
       "9    28.0   181.0  \n",
       "10   29.0   158.0  \n",
       "11   32.0   106.0  \n",
       "12   35.0   147.0  \n",
       "13   21.0    93.0  \n",
       "14   20.0    28.0  \n",
       "15    3.0    19.0  \n",
       "\n",
       "[16 rows x 27 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = str(BeautifulSoup(r.text).find(id=\"all_totals\"))\n",
    "formatted = html.replace(\"<!--\", \"\")\n",
    "table = BeautifulSoup(formatted).find(id=\"totals\").find_all('tr')\n",
    "\n",
    "headers = [u'Name', u'Age', u'G', u'GS', u'MP', u'FG', u'FGA', u'FG%', u'3P', u'3PA', u'3P%', u'2P', u'2PA', u'2P%', u'eFG%', u'FT', u'FTA', u'FT%', u'ORB', u'DRB', u'TRB', u'AST', u'STL', u'BLK', u'TOV', u'PF', u'PTS']\n",
    "\n",
    "player_data = []\n",
    "for row in table[1:]: # Remove header\n",
    "    data = [td.getText() for td in row.findAll('td')]\n",
    "    player_data.append(data)\n",
    "data_without_totals = player_data[:-1]\n",
    "formatted_data = [[data[0].encode('utf-8')] + [float(x) for x in data[1:]] for data in data_without_totals]\n",
    "pd.DataFrame(formatted_data, columns = headers)\n",
    "        #player_data = []\n",
    "#for row in table: # Remove header\n",
    " #   print(row.findAll('td').length)\n",
    "  #  data = [x.getText() for x in row.findAll('td')]\n",
    "   # formatted_data = [data[0].encode('utf-8')] + [float(x) for x in data[1:]]\n",
    "    #player_data.append(formattedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data from espn from 2003 to 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BASE_URL = 'http://www.espn.com/nba/team/stats/_/name/{0}/year/{1}'\n",
    "\n",
    "column_headers = [u'PLAYER', u'GP', u'GS', u'MIN', u'PPG', u'OFFR', u'DEFR', u'RPG', u'APG', u'SPG', u'BPG', u'TPG', u'FPG', u'A/TO', u'PER']\n",
    "\n",
    "def normalizeColumn(column):\n",
    "    theMax = column.max()\n",
    "    theMin = column.min()\n",
    "    normalizedColumn = [ (record - theMin) / (theMax - theMin) for record in column]\n",
    "    return normalizedColumn\n",
    "\n",
    "for year in range(2003, 2018):\n",
    "    player_data = []\n",
    "    for index, row in teams.iterrows():\n",
    "        r = requests.get(BASE_URL.format(row['prefix_1'], year))\n",
    "        table = BeautifulSoup(r.text).table\n",
    "        for row in table.find_all('tr')[2:][:-1]: # Remove header\n",
    "            data = [td.getText() for td in row.findAll('td')]\n",
    "            formattedData = [data[0].encode('utf-8')] + [float(x) for x in data[1:]] #formats the none-name fields to floats so we can do math\n",
    "            player_data.append(formattedData)\n",
    "    df = pd.DataFrame(player_data, columns=column_headers)\n",
    "    for column in df.iloc[:,1:]:\n",
    "        data = normalizeColumn(df[column])\n",
    "        df[column + \"_Normalized\"] = data\n",
    "    df['scores_Normalized'] = df.iloc[:,15:].apply(sum, axis = 1)\n",
    "    df.to_csv(\"player_stats_\" + str(year) + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize monster basketball data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalizeColumn(column):\n",
    "    theMax = column.max()\n",
    "    theMin = column.min()\n",
    "    normalizedColumn = [ (record - theMin) / float((theMax - theMin)) for record in column]\n",
    "    return normalizedColumn\n",
    "\n",
    "categories = ['p','a','3','r','s','b','to', 'fg%','ft%','fta']\n",
    "normed_categores = [cat + \"_Normalized\" for cat in categories]\n",
    "dates = range(2004, 2018)\n",
    "test = None\n",
    "for date in dates:\n",
    "    _file = 'monster_players_with_ranks_{0}.xls'.format(date)\n",
    "    df = pd.read_excel(_file)\n",
    "    for x in categories:\n",
    "        cat = df[x]\n",
    "        normed = normalizeColumn(cat)\n",
    "        df[x + \"_Normalized\"] = normed\n",
    "    scores = [sum([row[cat] for cat in normed_categores]) for label,row in df.iterrows()]\n",
    "    df['normalized_score'] = scores\n",
    "    df.to_csv(\"normalized_\" + _file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LR Model Using monster data and features to predict my normalized scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115\n",
      "1115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81393270127782247"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "features = ['Age', 'g', 'S%',\n",
    "       'm', 'p', '3', 'r', 'a', 's', 'b', 'fg%', 'fga', 'ft%', 'fta', 'to',\n",
    "       '3%', '3a', '2%', '2a', 'adjfg%', 'dr', 'or', '2d', '3d', 'fg',\n",
    "       'fgm', 'pf', 'ft', 'ftm', '3m', '2', 'ato', 'a+to', 'netft', 'to48',\n",
    "       '3s48', 'dpg', 'ppg', 'g.1', 's+b', 'p48', 'str', 'a-to', 'tech',\n",
    "       '3a/fga', 'ts%', 'USG', 'pV', '3V', 'rV', 'aV', 'sV', 'bV', 'fg%V',\n",
    "       'ft%V', 'toV', '3%V', '2%V', 'adjfg%V', 'drV', 'orV', '2dV', '3dV',\n",
    "       'fgV', 'fgaV', 'fgmV', 'pfV', 'ftV', 'ftaV', 'ftmV', 'mV', '3aV',\n",
    "       '3mV', '2V', '2aV', 'atoV', 'netftV', 'to48V', '3s48V', 'dpgV',\n",
    "       'ppgV', 's+bV', 'p48V', 'strV', 'a-toV', 'techV', '3a/fgaV', 'ts%V',\n",
    "       'p_Normalized', 'a_Normalized', '3_Normalized', 'r_Normalized',\n",
    "       's_Normalized', 'b_Normalized', 'to_Normalized', 'fg%_Normalized',\n",
    "       'ft%_Normalized', 'fta_Normalized', 'normalized_score']\n",
    "\n",
    "\n",
    "rankings = ['Y!Adp9', 'CBSAdp', 'CBSRank',\n",
    "       'FanTraxADP', 'Y!ORank', 'Y!Avg$', 'Y!Proj$', 'NBA Salary',\n",
    "       'ESPNAdp8', 'ESPNRank', 'ESPN$', 'ESPNProj$', 'Y!%', 'Value', 'Name', 'normalized_score']\n",
    "\n",
    "y = 'normalized_score'\n",
    "\n",
    "player_stats_by_year = []\n",
    "for year in range(2004, 2016):\n",
    "    if(year != 2017):\n",
    "        thisYear = pd.read_csv('normalized_monster_players_with_ranks_'+str(year)+\".xls\")\n",
    "        nextYear = pd.read_csv('normalized_monster_players_with_ranks_'+str(year+1)+\".xls\")\n",
    "        scores_next_year = nextYear[['Name', y]]\n",
    "        renamed_scores = scores_next_year.rename(index=str, columns={y: \"y\"})\n",
    "        merged = pd.merge(thisYear, renamed_scores, on='Name')\n",
    "        years = [year+1] * merged.shape[0]\n",
    "        merged['year'] = years\n",
    "        player_stats_by_year.append(merged)\n",
    "\n",
    "all_player_data = pd.concat(player_stats_by_year)\n",
    "lr = LinearRegression(n_jobs=-1)\n",
    "X = all_player_data\n",
    "y = all_player_data['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train_features = X_train[features]\n",
    "X_test_features = X_test[features]\n",
    "lr.fit(X_train_features,y_train)\n",
    "y_pred = [lr.predict([row]) for label,row in X_test_features.iterrows()]\n",
    "mean_squared_error(y_test, X_test['normalized_score'])\n",
    "mean_squared_error(y_test, y_pred)\n",
    "#zip(y_test, y_pred, X_test['Name'], X_test['year'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot mse as a function of the increasing that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1308d8c10>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJkiRJkiRJkiRJkqQy9P9XMVPiXUD7qwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1308649d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "features = ['Age', 'g', 'S%',\n",
    "       'm', 'p', '3', 'r', 'a', 's', 'b', 'fg%', 'fga', 'ft%', 'fta', 'to',\n",
    "       '3%', '3a', '2%', '2a', 'adjfg%', 'dr', 'or', '2d', '3d', 'fg',\n",
    "       'fgm', 'pf', 'ft', 'ftm', '3m', '2', 'ato', 'a+to', 'netft', 'to48',\n",
    "       '3s48', 'dpg', 'ppg', 'g.1', 's+b', 'p48', 'str', 'a-to', 'tech',\n",
    "       '3a/fga', 'ts%', 'USG', 'pV', '3V', 'rV', 'aV', 'sV', 'bV', 'fg%V',\n",
    "       'ft%V', 'toV', '3%V', '2%V', 'adjfg%V', 'drV', 'orV', '2dV', '3dV',\n",
    "       'fgV', 'fgaV', 'fgmV', 'pfV', 'ftV', 'ftaV', 'ftmV', 'mV', '3aV',\n",
    "       '3mV', '2V', '2aV', 'atoV', 'netftV', 'to48V', '3s48V', 'dpgV',\n",
    "       'ppgV', 's+bV', 'p48V', 'strV', 'a-toV', 'techV', '3a/fgaV', 'ts%V',\n",
    "       'p_Normalized', 'a_Normalized', '3_Normalized', 'r_Normalized',\n",
    "       's_Normalized', 'b_Normalized', 'to_Normalized', 'fg%_Normalized',\n",
    "       'ft%_Normalized', 'fta_Normalized', 'normalized_score']\n",
    "\n",
    "\n",
    "rankings = ['Y!Adp9', 'CBSAdp', 'CBSRank',\n",
    "       'FanTraxADP', 'Y!ORank', 'Y!Avg$', 'Y!Proj$', 'NBA Salary',\n",
    "       'ESPNAdp8', 'ESPNRank', 'ESPN$', 'ESPNProj$', 'Y!%', 'Value', 'Name', 'normalized_score']\n",
    "\n",
    "y_target = 'normalized_score'\n",
    "\n",
    "ranges = [range(x, 2016) for x in range(2004, 2016)]\n",
    "error = []\n",
    "for aRange in ranges:\n",
    "    player_stats_by_year = []\n",
    "    for year in aRange:\n",
    "        thisYear = pd.read_csv('normalized_monster_players_with_ranks_'+str(year)+\".xls\")\n",
    "        nextYear = pd.read_csv('normalized_monster_players_with_ranks_'+str(year+1)+\".xls\")\n",
    "        scores_next_year = nextYear[['Name', y_target]]\n",
    "        renamed_scores = scores_next_year.rename(index=str, columns={y_target: \"y\"})\n",
    "        merged = pd.merge(thisYear, renamed_scores, on='Name')\n",
    "        years = [year+1] * merged.shape[0]\n",
    "        merged['year'] = years\n",
    "        player_stats_by_year.append(merged)\n",
    "    all_player_data = pd.concat(player_stats_by_year)\n",
    "    lr = LinearRegression(n_jobs=-1)\n",
    "    X = all_player_data\n",
    "    y = all_player_data['y']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    X_train_features = X_train[features]\n",
    "    X_test_features = X_test[features]\n",
    "    lr.fit(X_train_features,y_train)\n",
    "    y_pred = [lr.predict([row]) for label,row in X_test_features.iterrows()]\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    error.append((len(aRange), mse))\n",
    "iters = zip(*error)[0]\n",
    "mse = zip(*error)[1]\n",
    "plt.scatter(x=iters, y=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection - show features with lowest p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, '2d'),\n",
       " (0.0, '3d'),\n",
       " (1.4829373501353286e-11, '2dV'),\n",
       " (7.5578910929343581e-08, 'a-to'),\n",
       " (2.2858880262755766e-07, '3dV'),\n",
       " (1.3338496774609976e-06, 'a-toV'),\n",
       " (2.6154364883860668e-06, 'tech'),\n",
       " (8.2449248678592329e-06, 'adjfg%V'),\n",
       " (1.4306240722490147e-05, 'ft%V'),\n",
       " (1.8258388302648957e-05, 'strV'),\n",
       " (4.0052246475975171e-05, 'ts%V'),\n",
       " (5.9496512320509645e-05, 'a_Normalized'),\n",
       " (8.0069726299928737e-05, 'atoV'),\n",
       " (0.00013952663611017826, 'aV'),\n",
       " (0.00014485803106399213, 'a'),\n",
       " (0.00030685944995041654, 'orV'),\n",
       " (0.0007827863988802081, 'p48V'),\n",
       " (0.00081517436678226526, 'or'),\n",
       " (0.0008347584037434046, 'netftV'),\n",
       " (0.0010235070627873588, 'netft'),\n",
       " (0.0010878858637949789, 'a+to'),\n",
       " (0.001373378252696717, '2V'),\n",
       " (0.0014440994379485142, 'b_Normalized'),\n",
       " (0.0017037072522539391, '2%V'),\n",
       " (0.0021207164602998364, 's_Normalized'),\n",
       " (0.0021730184015560333, '3%V'),\n",
       " (0.0026545142744476692, '2aV'),\n",
       " (0.0028431627616083105, 'fta_Normalized'),\n",
       " (0.0029344945761125983, 'b'),\n",
       " (0.0029368427109516472, '2'),\n",
       " (0.0033125914603880165, 'ftV'),\n",
       " (0.0037943547187437709, 'ft'),\n",
       " (0.0047949157288010129, 'ftaV'),\n",
       " (0.0049952525636460833, '2a'),\n",
       " (0.0054422510867888603, 'ftmV'),\n",
       " (0.0057204272153506784, 'bV'),\n",
       " (0.0060797438438714756, 'fta'),\n",
       " (0.0073375097854341403, 'ftm'),\n",
       " (0.0079495226201046956, 's'),\n",
       " (0.0084731613526997061, 'toV'),\n",
       " (0.0088828255239374841, 'sV'),\n",
       " (0.01013609678865807, 'to48V'),\n",
       " (0.01045723977855631, 'ppgV'),\n",
       " (0.012357905418571565, 'to'),\n",
       " (0.013577988903528891, 'to_Normalized'),\n",
       " (0.01357906203008988, 's+b'),\n",
       " (0.013911739341037342, 'fg%V'),\n",
       " (0.015360675106872309, 'r_Normalized'),\n",
       " (0.016864305537610924, 'rV'),\n",
       " (0.026106583560055147, 'r'),\n",
       " (0.031982484861073475, 's+bV'),\n",
       " (0.033520314923097407, '3s48V'),\n",
       " (0.036487024781816993, 'fgV'),\n",
       " (0.038718801245153568, 'drV'),\n",
       " (0.043311687833639284, 'dpgV'),\n",
       " (0.045807228250553417, 'dpg'),\n",
       " (0.045977792129775943, 'fg'),\n",
       " (0.049493297305368875, 'ppg'),\n",
       " (0.053462848367807229, 'dr'),\n",
       " (0.054854377371561666, 'pV'),\n",
       " (0.059089022513875357, 'p'),\n",
       " (0.059656760351510664, 'p_Normalized'),\n",
       " (0.062341534200123956, '3a/fgaV'),\n",
       " (0.074501967012275655, 'fgaV'),\n",
       " (0.078720114497655369, 'fga'),\n",
       " (0.10801364879214123, 'fgm'),\n",
       " (0.11190282525362856, 'ato'),\n",
       " (0.11293044838313129, 'fgmV'),\n",
       " (0.11665585777316506, 'techV'),\n",
       " (0.1699168920447798, 'normalized_score'),\n",
       " (0.17978478446252755, 'pfV'),\n",
       " (0.22867498348157164, 'pf'),\n",
       " (0.29657399457476941, 'm'),\n",
       " (0.32580484895202194, 'mV'),\n",
       " (0.3270469784570284, '3mV'),\n",
       " (0.33369375537755908, '3_Normalized'),\n",
       " (0.33405260108312335, '3m'),\n",
       " (0.34380903770575144, '3aV'),\n",
       " (0.35388797825263107, '3V'),\n",
       " (0.36105711958604453, '3a'),\n",
       " (0.38757368815987903, '3'),\n",
       " (0.44847866893467375, 'str'),\n",
       " (0.54075394661767529, 'to48'),\n",
       " (0.59934958159885143, 'S%'),\n",
       " (0.65224507007778731, 'Age'),\n",
       " (0.69412001956753722, '3%'),\n",
       " (0.70644618143232341, 'p48'),\n",
       " (0.81288827864017743, 'g'),\n",
       " (0.81288827864017743, 'g.1'),\n",
       " (0.81328201540308609, 'USG'),\n",
       " (0.84409001660459326, '3s48'),\n",
       " (0.98100313992321919, '3a/fga'),\n",
       " (0.9966766062383785, 'ft%'),\n",
       " (0.9966766062383785, 'ft%_Normalized'),\n",
       " (0.99999999969985187, 'fg%_Normalized'),\n",
       " (0.99999999999570632, 'ts%'),\n",
       " (0.99999999999797695, '2%'),\n",
       " (0.99999999999917888, 'fg%'),\n",
       " (0.9999999999999164, 'adjfg%')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb = SelectKBest()\n",
    "sb.fit(X[features].as_matrix(), np.array(y))\n",
    "scores = zip(sb.pvalues_, features)\n",
    "scores.sort(key=lambda tup: tup[0])\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using Keras Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3788 samples, validate on 669 samples\n",
      "Epoch 1/20\n",
      "3788/3788 [==============================] - 0s - loss: 4.5817 - val_loss: 1.5486\n",
      "Epoch 2/20\n",
      "3788/3788 [==============================] - 0s - loss: 1.2498 - val_loss: 0.6886\n",
      "Epoch 3/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.8979 - val_loss: 0.6595\n",
      "Epoch 4/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.8529 - val_loss: 0.5485\n",
      "Epoch 5/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.9104 - val_loss: 0.5847\n",
      "Epoch 6/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.8223 - val_loss: 0.6000\n",
      "Epoch 7/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.8373 - val_loss: 0.6379\n",
      "Epoch 8/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7344 - val_loss: 0.5348\n",
      "Epoch 9/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7925 - val_loss: 0.5679\n",
      "Epoch 10/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7551 - val_loss: 0.6297\n",
      "Epoch 11/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7763 - val_loss: 0.6892\n",
      "Epoch 12/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7793 - val_loss: 0.5357\n",
      "Epoch 13/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7294 - val_loss: 0.6881\n",
      "Epoch 14/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.8324 - val_loss: 0.5466\n",
      "Epoch 15/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7451 - val_loss: 0.5279\n",
      "Epoch 16/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7477 - val_loss: 0.5427\n",
      "Epoch 17/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7021 - val_loss: 0.6627\n",
      "Epoch 18/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7628 - val_loss: 0.5226\n",
      "Epoch 19/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7441 - val_loss: 0.7293\n",
      "Epoch 20/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7235 - val_loss: 0.7777\n",
      "Train on 3465 samples, validate on 612 samples\n",
      "Epoch 1/20\n",
      "3465/3465 [==============================] - 0s - loss: 26.1398 - val_loss: 1.9527\n",
      "Epoch 2/20\n",
      "3465/3465 [==============================] - 0s - loss: 1.9078 - val_loss: 0.8069\n",
      "Epoch 3/20\n",
      "3465/3465 [==============================] - 0s - loss: 1.0614 - val_loss: 0.8010\n",
      "Epoch 4/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.9288 - val_loss: 0.6293\n",
      "Epoch 5/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.8218 - val_loss: 0.6106\n",
      "Epoch 6/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.8170 - val_loss: 0.6140\n",
      "Epoch 7/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.8256 - val_loss: 0.7605\n",
      "Epoch 8/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.7716 - val_loss: 0.5573\n",
      "Epoch 9/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.7643 - val_loss: 0.5731\n",
      "Epoch 10/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.7675 - val_loss: 0.5733\n",
      "Epoch 11/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.7430 - val_loss: 0.6436\n",
      "Epoch 12/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.7688 - val_loss: 0.5826\n",
      "Epoch 13/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.7215 - val_loss: 0.5991\n",
      "Epoch 14/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.7316 - val_loss: 0.5350\n",
      "Epoch 15/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.7491 - val_loss: 0.5753\n",
      "Epoch 16/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.7529 - val_loss: 0.5577\n",
      "Epoch 17/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.7185 - val_loss: 0.5344\n",
      "Epoch 18/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.7327 - val_loss: 0.5677\n",
      "Epoch 19/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.7396 - val_loss: 0.5582\n",
      "Epoch 20/20\n",
      "3465/3465 [==============================] - 0s - loss: 0.7489 - val_loss: 0.5276\n",
      "Train on 3155 samples, validate on 557 samples\n",
      "Epoch 1/20\n",
      "3155/3155 [==============================] - 0s - loss: 2.8919 - val_loss: 0.6938\n",
      "Epoch 2/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.8316 - val_loss: 0.6533\n",
      "Epoch 3/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7828 - val_loss: 0.5435\n",
      "Epoch 4/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7808 - val_loss: 0.5776\n",
      "Epoch 5/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7580 - val_loss: 0.5550\n",
      "Epoch 6/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7916 - val_loss: 0.6640\n",
      "Epoch 7/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7234 - val_loss: 0.5831\n",
      "Epoch 8/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7631 - val_loss: 0.5769\n",
      "Epoch 9/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7734 - val_loss: 0.5642\n",
      "Epoch 10/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7605 - val_loss: 0.6086\n",
      "Epoch 11/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7522 - val_loss: 0.5739\n",
      "Epoch 12/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7329 - val_loss: 0.5554\n",
      "Epoch 13/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7576 - val_loss: 0.5398\n",
      "Epoch 14/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7392 - val_loss: 0.7295\n",
      "Epoch 15/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7373 - val_loss: 0.6387\n",
      "Epoch 16/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7567 - val_loss: 0.5673\n",
      "Epoch 17/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7221 - val_loss: 0.5801\n",
      "Epoch 18/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7400 - val_loss: 0.7226\n",
      "Epoch 19/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7411 - val_loss: 0.7291\n",
      "Epoch 20/20\n",
      "3155/3155 [==============================] - 0s - loss: 0.7067 - val_loss: 0.5911\n",
      "Train on 2844 samples, validate on 502 samples\n",
      "Epoch 1/20\n",
      "2844/2844 [==============================] - 0s - loss: 3.0323 - val_loss: 1.1812\n",
      "Epoch 2/20\n",
      "2844/2844 [==============================] - 0s - loss: 1.1852 - val_loss: 0.7900\n",
      "Epoch 3/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.8950 - val_loss: 0.6712\n",
      "Epoch 4/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.8982 - val_loss: 0.7268\n",
      "Epoch 5/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.8159 - val_loss: 0.6027\n",
      "Epoch 6/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.7820 - val_loss: 0.5921\n",
      "Epoch 7/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.7675 - val_loss: 0.6869\n",
      "Epoch 8/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.7564 - val_loss: 0.5547\n",
      "Epoch 9/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.7483 - val_loss: 0.5510\n",
      "Epoch 10/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.7689 - val_loss: 0.5455\n",
      "Epoch 11/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.7539 - val_loss: 0.5570\n",
      "Epoch 12/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.7307 - val_loss: 0.5522\n",
      "Epoch 13/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.7308 - val_loss: 0.5660\n",
      "Epoch 14/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.7183 - val_loss: 0.6598\n",
      "Epoch 15/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.7177 - val_loss: 0.5680\n",
      "Epoch 16/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.7542 - val_loss: 0.5345\n",
      "Epoch 17/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.7380 - val_loss: 0.5712\n",
      "Epoch 18/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.7093 - val_loss: 0.5600\n",
      "Epoch 19/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.7154 - val_loss: 0.5748\n",
      "Epoch 20/20\n",
      "2844/2844 [==============================] - 0s - loss: 0.7224 - val_loss: 0.5476\n",
      "Train on 2529 samples, validate on 447 samples\n",
      "Epoch 1/20\n",
      "2529/2529 [==============================] - 0s - loss: 20.7200 - val_loss: 1.9103\n",
      "Epoch 2/20\n",
      "2529/2529 [==============================] - 0s - loss: 1.6899 - val_loss: 0.9920\n",
      "Epoch 3/20\n",
      "2529/2529 [==============================] - 0s - loss: 1.1244 - val_loss: 0.8345\n",
      "Epoch 4/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.9847 - val_loss: 0.7000\n",
      "Epoch 5/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.9452 - val_loss: 0.6749\n",
      "Epoch 6/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.8852 - val_loss: 0.6569\n",
      "Epoch 7/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.8472 - val_loss: 0.6331\n",
      "Epoch 8/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.8217 - val_loss: 0.6583\n",
      "Epoch 9/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.8105 - val_loss: 0.6748\n",
      "Epoch 10/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.8563 - val_loss: 0.6475\n",
      "Epoch 11/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.7709 - val_loss: 0.7140\n",
      "Epoch 12/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.7864 - val_loss: 0.6158\n",
      "Epoch 13/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.7527 - val_loss: 0.6911\n",
      "Epoch 14/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.7753 - val_loss: 0.8424\n",
      "Epoch 15/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.7625 - val_loss: 0.5881\n",
      "Epoch 16/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.7491 - val_loss: 0.5680\n",
      "Epoch 17/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.7911 - val_loss: 0.6014\n",
      "Epoch 18/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.7854 - val_loss: 0.6012\n",
      "Epoch 19/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.7392 - val_loss: 0.7843\n",
      "Epoch 20/20\n",
      "2529/2529 [==============================] - 0s - loss: 0.7657 - val_loss: 0.5603\n",
      "Train on 2218 samples, validate on 392 samples\n",
      "Epoch 1/20\n",
      "2218/2218 [==============================] - 0s - loss: 6.1399 - val_loss: 1.4429\n",
      "Epoch 2/20\n",
      "2218/2218 [==============================] - 0s - loss: 1.3286 - val_loss: 0.8991\n",
      "Epoch 3/20\n",
      "2218/2218 [==============================] - 0s - loss: 1.0349 - val_loss: 0.8106\n",
      "Epoch 4/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.9458 - val_loss: 0.6516\n",
      "Epoch 5/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.8088 - val_loss: 0.6150\n",
      "Epoch 6/20\n",
      "2218/2218 [==============================] - 0s - loss: 1.1179 - val_loss: 1.2457\n",
      "Epoch 7/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.8839 - val_loss: 1.0730\n",
      "Epoch 8/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.8621 - val_loss: 0.5490\n",
      "Epoch 9/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.8864 - val_loss: 1.2661\n",
      "Epoch 10/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.8045 - val_loss: 0.7992\n",
      "Epoch 11/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.8160 - val_loss: 0.6575\n",
      "Epoch 12/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.7365 - val_loss: 0.5394\n",
      "Epoch 13/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.7495 - val_loss: 0.5393\n",
      "Epoch 14/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.7551 - val_loss: 0.5589\n",
      "Epoch 15/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.7223 - val_loss: 0.7008\n",
      "Epoch 16/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.8193 - val_loss: 0.7583\n",
      "Epoch 17/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.7979 - val_loss: 0.5496\n",
      "Epoch 18/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.7498 - val_loss: 0.9749\n",
      "Epoch 19/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.7186 - val_loss: 0.5968\n",
      "Epoch 20/20\n",
      "2218/2218 [==============================] - 0s - loss: 0.7703 - val_loss: 0.6032\n",
      "Train on 1908 samples, validate on 337 samples\n",
      "Epoch 1/20\n",
      "1908/1908 [==============================] - 0s - loss: 8.8395 - val_loss: 1.3440\n",
      "Epoch 2/20\n",
      "1908/1908 [==============================] - 0s - loss: 1.2497 - val_loss: 0.9482\n",
      "Epoch 3/20\n",
      "1908/1908 [==============================] - 0s - loss: 1.1847 - val_loss: 0.9106\n",
      "Epoch 4/20\n",
      "1908/1908 [==============================] - 0s - loss: 1.0017 - val_loss: 0.8518\n",
      "Epoch 5/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.9955 - val_loss: 0.8019\n",
      "Epoch 6/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.9657 - val_loss: 0.7652\n",
      "Epoch 7/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.9282 - val_loss: 0.6671\n",
      "Epoch 8/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.8951 - val_loss: 0.7519\n",
      "Epoch 9/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.9447 - val_loss: 0.6268\n",
      "Epoch 10/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.8312 - val_loss: 0.7020\n",
      "Epoch 11/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.8615 - val_loss: 0.6132\n",
      "Epoch 12/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.7791 - val_loss: 0.7945\n",
      "Epoch 13/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.8066 - val_loss: 0.5867\n",
      "Epoch 14/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.7989 - val_loss: 0.7764\n",
      "Epoch 15/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.7766 - val_loss: 0.6458\n",
      "Epoch 16/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.7800 - val_loss: 0.7011\n",
      "Epoch 17/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.7713 - val_loss: 0.5703\n",
      "Epoch 18/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.7641 - val_loss: 0.6252\n",
      "Epoch 19/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.8158 - val_loss: 0.9121\n",
      "Epoch 20/20\n",
      "1908/1908 [==============================] - 0s - loss: 0.7832 - val_loss: 0.6048\n",
      "Train on 1592 samples, validate on 282 samples\n",
      "Epoch 1/20\n",
      "1592/1592 [==============================] - 0s - loss: 10.2485 - val_loss: 1.5425\n",
      "Epoch 2/20\n",
      "1592/1592 [==============================] - 0s - loss: 1.7331 - val_loss: 1.0027\n",
      "Epoch 3/20\n",
      "1592/1592 [==============================] - 0s - loss: 1.1582 - val_loss: 0.8052\n",
      "Epoch 4/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.9752 - val_loss: 0.9440\n",
      "Epoch 5/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.8971 - val_loss: 0.6749\n",
      "Epoch 6/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.8451 - val_loss: 0.5789\n",
      "Epoch 7/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.8338 - val_loss: 0.6944\n",
      "Epoch 8/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.8046 - val_loss: 0.8497\n",
      "Epoch 9/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.8009 - val_loss: 0.6274\n",
      "Epoch 10/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.7689 - val_loss: 0.5992\n",
      "Epoch 11/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.7723 - val_loss: 0.5808\n",
      "Epoch 12/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.7833 - val_loss: 0.6366\n",
      "Epoch 13/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.8021 - val_loss: 0.6652\n",
      "Epoch 14/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.7921 - val_loss: 0.7324\n",
      "Epoch 15/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.7964 - val_loss: 0.8810\n",
      "Epoch 16/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.7813 - val_loss: 0.6802\n",
      "Epoch 17/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.7471 - val_loss: 0.5534\n",
      "Epoch 18/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.7762 - val_loss: 0.6693\n",
      "Epoch 19/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.7311 - val_loss: 0.8551\n",
      "Epoch 20/20\n",
      "1592/1592 [==============================] - 0s - loss: 0.8097 - val_loss: 0.6480\n",
      "Train on 1270 samples, validate on 225 samples\n",
      "Epoch 1/20\n",
      "1270/1270 [==============================] - 0s - loss: 5.7120 - val_loss: 1.3651\n",
      "Epoch 2/20\n",
      "1270/1270 [==============================] - 0s - loss: 1.6920 - val_loss: 1.1130\n",
      "Epoch 3/20\n",
      "1270/1270 [==============================] - 0s - loss: 1.2284 - val_loss: 0.8500\n",
      "Epoch 4/20\n",
      "1270/1270 [==============================] - 0s - loss: 1.0655 - val_loss: 0.9096\n",
      "Epoch 5/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.9575 - val_loss: 0.7546\n",
      "Epoch 6/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.8657 - val_loss: 0.6135\n",
      "Epoch 7/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.8693 - val_loss: 0.6465\n",
      "Epoch 8/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.8406 - val_loss: 0.8332\n",
      "Epoch 9/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.8054 - val_loss: 0.6664\n",
      "Epoch 10/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.7835 - val_loss: 0.5969\n",
      "Epoch 11/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.7609 - val_loss: 0.5751\n",
      "Epoch 12/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.8446 - val_loss: 0.6277\n",
      "Epoch 13/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.8055 - val_loss: 0.5771\n",
      "Epoch 14/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.7694 - val_loss: 0.6647\n",
      "Epoch 15/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.7675 - val_loss: 0.7085\n",
      "Epoch 16/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.7858 - val_loss: 0.5654\n",
      "Epoch 17/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.9693 - val_loss: 0.6087\n",
      "Epoch 18/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.7645 - val_loss: 0.5695\n",
      "Epoch 19/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.7922 - val_loss: 0.7136\n",
      "Epoch 20/20\n",
      "1270/1270 [==============================] - 0s - loss: 0.7537 - val_loss: 0.7005\n",
      "Train on 961 samples, validate on 170 samples\n",
      "Epoch 1/20\n",
      "961/961 [==============================] - 0s - loss: 2.4971 - val_loss: 1.8324\n",
      "Epoch 2/20\n",
      "961/961 [==============================] - 0s - loss: 1.4632 - val_loss: 1.1233\n",
      "Epoch 3/20\n",
      "961/961 [==============================] - 0s - loss: 1.1474 - val_loss: 1.0308\n",
      "Epoch 4/20\n",
      "961/961 [==============================] - 0s - loss: 0.9540 - val_loss: 0.7979\n",
      "Epoch 5/20\n",
      "961/961 [==============================] - 0s - loss: 0.8663 - val_loss: 0.8014\n",
      "Epoch 6/20\n",
      "961/961 [==============================] - 0s - loss: 0.8916 - val_loss: 0.7758\n",
      "Epoch 7/20\n",
      "961/961 [==============================] - 0s - loss: 0.8481 - val_loss: 0.7090\n",
      "Epoch 8/20\n",
      "961/961 [==============================] - 0s - loss: 0.8244 - val_loss: 0.6833\n",
      "Epoch 9/20\n",
      "961/961 [==============================] - 0s - loss: 0.7894 - val_loss: 0.6950\n",
      "Epoch 10/20\n",
      "961/961 [==============================] - 0s - loss: 0.9387 - val_loss: 0.7755\n",
      "Epoch 11/20\n",
      "961/961 [==============================] - 0s - loss: 0.8019 - val_loss: 0.6690\n",
      "Epoch 12/20\n",
      "961/961 [==============================] - 0s - loss: 0.7397 - val_loss: 0.6648\n",
      "Epoch 13/20\n",
      "961/961 [==============================] - 0s - loss: 0.7251 - val_loss: 0.6505\n",
      "Epoch 14/20\n",
      "961/961 [==============================] - 0s - loss: 0.7309 - val_loss: 0.6569\n",
      "Epoch 15/20\n",
      "961/961 [==============================] - 0s - loss: 0.6949 - val_loss: 0.6536\n",
      "Epoch 16/20\n",
      "961/961 [==============================] - 0s - loss: 0.6847 - val_loss: 0.6456\n",
      "Epoch 17/20\n",
      "961/961 [==============================] - 0s - loss: 0.8904 - val_loss: 0.6454\n",
      "Epoch 18/20\n",
      "961/961 [==============================] - 0s - loss: 0.7095 - val_loss: 0.7504\n",
      "Epoch 19/20\n",
      "961/961 [==============================] - 0s - loss: 0.6733 - val_loss: 0.6355\n",
      "Epoch 20/20\n",
      "961/961 [==============================] - 0s - loss: 0.7503 - val_loss: 0.6703\n",
      "Train on 653 samples, validate on 116 samples\n",
      "Epoch 1/20\n",
      "653/653 [==============================] - 0s - loss: 15.7175 - val_loss: 1.3446\n",
      "Epoch 2/20\n",
      "653/653 [==============================] - 0s - loss: 1.6496 - val_loss: 1.9961\n",
      "Epoch 3/20\n",
      "653/653 [==============================] - 0s - loss: 1.2564 - val_loss: 1.6394\n",
      "Epoch 4/20\n",
      "653/653 [==============================] - 0s - loss: 1.1954 - val_loss: 1.6748\n",
      "Epoch 5/20\n",
      "653/653 [==============================] - 0s - loss: 1.1598 - val_loss: 1.6071\n",
      "Epoch 6/20\n",
      "653/653 [==============================] - 0s - loss: 1.1339 - val_loss: 1.5711\n",
      "Epoch 7/20\n",
      "653/653 [==============================] - 0s - loss: 1.1108 - val_loss: 1.5237\n",
      "Epoch 8/20\n",
      "653/653 [==============================] - 0s - loss: 1.0887 - val_loss: 1.3961\n",
      "Epoch 9/20\n",
      "653/653 [==============================] - 0s - loss: 1.0408 - val_loss: 1.2246\n",
      "Epoch 10/20\n",
      "653/653 [==============================] - 0s - loss: 0.9592 - val_loss: 0.8570\n",
      "Epoch 11/20\n",
      "653/653 [==============================] - 0s - loss: 0.8838 - val_loss: 0.7972\n",
      "Epoch 12/20\n",
      "653/653 [==============================] - 0s - loss: 0.8462 - val_loss: 0.7248\n",
      "Epoch 13/20\n",
      "653/653 [==============================] - 0s - loss: 0.8445 - val_loss: 0.7276\n",
      "Epoch 14/20\n",
      "653/653 [==============================] - 0s - loss: 0.8279 - val_loss: 0.6936\n",
      "Epoch 15/20\n",
      "653/653 [==============================] - 0s - loss: 0.7995 - val_loss: 0.7019\n",
      "Epoch 16/20\n",
      "653/653 [==============================] - 0s - loss: 0.7910 - val_loss: 0.6828\n",
      "Epoch 17/20\n",
      "653/653 [==============================] - 0s - loss: 0.7688 - val_loss: 0.6717\n",
      "Epoch 18/20\n",
      "653/653 [==============================] - 0s - loss: 0.7482 - val_loss: 0.6820\n",
      "Epoch 19/20\n",
      "653/653 [==============================] - 0s - loss: 0.7469 - val_loss: 0.6975\n",
      "Epoch 20/20\n",
      "653/653 [==============================] - 0s - loss: 0.8189 - val_loss: 0.6278\n",
      "Train on 328 samples, validate on 59 samples\n",
      "Epoch 1/20\n",
      "328/328 [==============================] - 0s - loss: 5.6098 - val_loss: 2.3952\n",
      "Epoch 2/20\n",
      "328/328 [==============================] - 0s - loss: 2.1047 - val_loss: 2.0448\n",
      "Epoch 3/20\n",
      "328/328 [==============================] - 0s - loss: 1.5333 - val_loss: 1.9321\n",
      "Epoch 4/20\n",
      "328/328 [==============================] - 0s - loss: 1.2903 - val_loss: 1.8721\n",
      "Epoch 5/20\n",
      "328/328 [==============================] - 0s - loss: 1.0826 - val_loss: 1.8254\n",
      "Epoch 6/20\n",
      "328/328 [==============================] - 0s - loss: 1.1755 - val_loss: 1.8511\n",
      "Epoch 7/20\n",
      "328/328 [==============================] - 0s - loss: 1.0458 - val_loss: 1.8319\n",
      "Epoch 8/20\n",
      "328/328 [==============================] - 0s - loss: 0.9070 - val_loss: 1.7341\n",
      "Epoch 9/20\n",
      "328/328 [==============================] - 0s - loss: 0.8579 - val_loss: 1.6592\n",
      "Epoch 10/20\n",
      "328/328 [==============================] - 0s - loss: 0.8362 - val_loss: 1.6282\n",
      "Epoch 11/20\n",
      "328/328 [==============================] - 0s - loss: 0.7712 - val_loss: 1.5848\n",
      "Epoch 12/20\n",
      "328/328 [==============================] - 0s - loss: 0.7573 - val_loss: 1.5235\n",
      "Epoch 13/20\n",
      "328/328 [==============================] - 0s - loss: 0.6909 - val_loss: 1.4309\n",
      "Epoch 14/20\n",
      "328/328 [==============================] - 0s - loss: 0.6976 - val_loss: 1.3762\n",
      "Epoch 15/20\n",
      "328/328 [==============================] - 0s - loss: 0.7658 - val_loss: 1.3436\n",
      "Epoch 16/20\n",
      "328/328 [==============================] - 0s - loss: 0.8918 - val_loss: 1.3157\n",
      "Epoch 17/20\n",
      "328/328 [==============================] - 0s - loss: 0.7994 - val_loss: 1.3072\n",
      "Epoch 18/20\n",
      "328/328 [==============================] - 0s - loss: 0.6541 - val_loss: 1.2804\n",
      "Epoch 19/20\n",
      "328/328 [==============================] - 0s - loss: 0.6389 - val_loss: 1.2870\n",
      "Epoch 20/20\n",
      "328/328 [==============================] - 0s - loss: 0.6197 - val_loss: 1.2645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x137ebf2d0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1381f9f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "ranges = [range(x, 2016) for x in range(2004, 2016)]\n",
    "error = []\n",
    "for aRange in ranges:\n",
    "    player_stats_by_year = []\n",
    "    for year in aRange:\n",
    "        thisYear = pd.read_csv('normalized_monster_players_with_ranks_'+str(year)+\".xls\")\n",
    "        nextYear = pd.read_csv('normalized_monster_players_with_ranks_'+str(year+1)+\".xls\")\n",
    "        scores_next_year = nextYear[['Name', y_target]]\n",
    "        renamed_scores = scores_next_year.rename(index=str, columns={y_target: \"y\"})\n",
    "        merged = pd.merge(thisYear, renamed_scores, on='Name')\n",
    "        years = [year+1] * merged.shape[0]\n",
    "        merged['year'] = years\n",
    "        player_stats_by_year.append(merged)\n",
    "    all_player_data = pd.concat(player_stats_by_year)\n",
    "    X = all_player_data\n",
    "    y = all_player_data['y']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    X_train_features = X_train[features]\n",
    "    X_test_features = X_test[features]\n",
    "    inputs = Input(shape=(shape,))\n",
    "    hidden1 = Dense(10,init='normal', activation='relu')(inputs)\n",
    "    predictions = Dense(1, init='normal')(hidden1)\n",
    "    model = Model(input=inputs, output=predictions)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X[features].as_matrix(), y,\n",
    "              nb_epoch=20,\n",
    "              validation_split=.15)\n",
    "    y_pred = [model.predict(np.array(row).reshape(1, 99))[0][0] for label,row in X_test_features.iterrows()]\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    error.append((len(aRange), mse))\n",
    "iters = zip(*error)[0]\n",
    "mse = zip(*error)[1]\n",
    "plt.scatter(x=iters, y=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3788 samples, validate on 669 samples\n",
      "Epoch 1/20\n",
      "3788/3788 [==============================] - 0s - loss: 8.2200 - val_loss: 2.3706\n",
      "Epoch 2/20\n",
      "3788/3788 [==============================] - 0s - loss: 1.7796 - val_loss: 1.3956\n",
      "Epoch 3/20\n",
      "3788/3788 [==============================] - 0s - loss: 1.1985 - val_loss: 0.8304\n",
      "Epoch 4/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.9550 - val_loss: 0.7093\n",
      "Epoch 5/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.8439 - val_loss: 0.6223\n",
      "Epoch 6/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.8230 - val_loss: 0.6121\n",
      "Epoch 7/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7826 - val_loss: 0.9171\n",
      "Epoch 8/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.8007 - val_loss: 0.5640\n",
      "Epoch 9/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.8549 - val_loss: 0.6240\n",
      "Epoch 10/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7706 - val_loss: 0.5650\n",
      "Epoch 11/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7913 - val_loss: 0.5395\n",
      "Epoch 12/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7577 - val_loss: 0.5474\n",
      "Epoch 13/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.8389 - val_loss: 0.5923\n",
      "Epoch 14/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.8322 - val_loss: 0.5650\n",
      "Epoch 15/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7396 - val_loss: 0.5995\n",
      "Epoch 16/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7563 - val_loss: 0.5499\n",
      "Epoch 17/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7385 - val_loss: 0.7383\n",
      "Epoch 18/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7569 - val_loss: 0.5877\n",
      "Epoch 19/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7191 - val_loss: 0.5558\n",
      "Epoch 20/20\n",
      "3788/3788 [==============================] - 0s - loss: 0.7483 - val_loss: 0.7276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76335797823727125"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(shape,))\n",
    "hidden1 = Dense(10,init='normal', activation='relu')(inputs)\n",
    "predictions = Dense(1, init='normal')(hidden1)\n",
    "model = Model(input=inputs, output=predictions)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X[features].as_matrix(), y,\n",
    "          nb_epoch=20,\n",
    "          validation_split=.15)\n",
    "\n",
    "y_pred = [model.predict(np.array(row).reshape(1, 99))[0][0] for label,row in X_test_features.iterrows()]\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2840 samples, validate on 502 samples\n",
      "Epoch 1/10\n",
      "2840/2840 [==============================] - 0s - loss: 3.2912 - val_loss: 1.3485\n",
      "Epoch 2/10\n",
      "2840/2840 [==============================] - 0s - loss: 1.1649 - val_loss: 1.2210\n",
      "Epoch 3/10\n",
      "2840/2840 [==============================] - 0s - loss: 0.9603 - val_loss: 0.8507\n",
      "Epoch 4/10\n",
      "2840/2840 [==============================] - 0s - loss: 0.7664 - val_loss: 0.7606\n",
      "Epoch 5/10\n",
      "2840/2840 [==============================] - 0s - loss: 0.7705 - val_loss: 0.7957\n",
      "Epoch 6/10\n",
      "2840/2840 [==============================] - 0s - loss: 0.7362 - val_loss: 0.7548\n",
      "Epoch 7/10\n",
      "2840/2840 [==============================] - 0s - loss: 0.7633 - val_loss: 0.7666\n",
      "Epoch 8/10\n",
      "2840/2840 [==============================] - 0s - loss: 0.7390 - val_loss: 0.7435\n",
      "Epoch 9/10\n",
      "2840/2840 [==============================] - 0s - loss: 0.7104 - val_loss: 0.7050\n",
      "Epoch 10/10\n",
      "2840/2840 [==============================] - 0s - loss: 0.7396 - val_loss: 0.7211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72681770363054476"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(shape,))\n",
    "hidden1 = Dense(10,init='normal', activation='relu')(inputs)\n",
    "hidden2 = Dense(10,init='normal', activation='relu')(hidden1)\n",
    "hidden3 = Dense(10,init='normal', activation='relu')(hidden2)\n",
    "predictions = Dense(1, init='normal')(hidden3)\n",
    "model = Model(input=inputs, output=predictions)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train_features.as_matrix(), y_train,\n",
    "          nb_epoch=10,\n",
    "          validation_split=.15)\n",
    "\n",
    "y_pred = [model.predict(np.array(row).reshape(1, 99))[0][0] for label,row in X_test_features.iterrows()]\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zip(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James Harden</td>\n",
       "      <td>5.944705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>5.727851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>4.634020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>4.541718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>4.537194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>4.444879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>John Wall</td>\n",
       "      <td>4.430092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Isaiah Thomas</td>\n",
       "      <td>4.419591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>4.344743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>4.219548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>4.214816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kawhi Leonard</td>\n",
       "      <td>4.173067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>4.115089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>3.967767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>3.887852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>3.868522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Jeff Teague</td>\n",
       "      <td>3.852910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>3.843155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>3.831783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CJ McCollum</td>\n",
       "      <td>3.768428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Marc Gasol</td>\n",
       "      <td>3.762130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Paul George</td>\n",
       "      <td>3.737009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Brook Lopez</td>\n",
       "      <td>3.724822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>3.691913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mike Conley</td>\n",
       "      <td>3.656830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Carmelo Anthony</td>\n",
       "      <td>3.593797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Lou Williams</td>\n",
       "      <td>3.572137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Nicolas Batum</td>\n",
       "      <td>3.555573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>3.553334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gordon Hayward</td>\n",
       "      <td>3.549064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Cole Aldrich</td>\n",
       "      <td>1.461078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>Chinanu Onuaku</td>\n",
       "      <td>1.457253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Okaro White</td>\n",
       "      <td>1.446756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>Daniel Ochefu</td>\n",
       "      <td>1.434554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Jordan Hill</td>\n",
       "      <td>1.433222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Semaj Christon</td>\n",
       "      <td>1.428717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Omer Asik</td>\n",
       "      <td>1.425324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>CJ Wilcox</td>\n",
       "      <td>1.418759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Deyonta Davis</td>\n",
       "      <td>1.413589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>Derrick Jones</td>\n",
       "      <td>1.410955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Delon Wright</td>\n",
       "      <td>1.404750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Rakeem Christmas</td>\n",
       "      <td>1.399864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Damian Jones</td>\n",
       "      <td>1.388262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Bryn Forbes</td>\n",
       "      <td>1.386954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Jakob Poeltl</td>\n",
       "      <td>1.386680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Joel Anthony</td>\n",
       "      <td>1.386125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>Nick Collison</td>\n",
       "      <td>1.381941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>Kyle Singler</td>\n",
       "      <td>1.372502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Steve Novak</td>\n",
       "      <td>1.368734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Stephen Zimmerman</td>\n",
       "      <td>1.344804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Lavoy Allen</td>\n",
       "      <td>1.344350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Ian Mahinmi</td>\n",
       "      <td>1.331911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>Michael Gbinije</td>\n",
       "      <td>1.318762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Christian Wood</td>\n",
       "      <td>1.290884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Georgios Papagiannis</td>\n",
       "      <td>1.289636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Bruno Caboclo</td>\n",
       "      <td>1.284032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Marshall Plumlee</td>\n",
       "      <td>1.235881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>Mike Tobey</td>\n",
       "      <td>1.214527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>RJ Hunter</td>\n",
       "      <td>1.011761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Danuel House</td>\n",
       "      <td>0.960622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>444 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name     score\n",
       "1             James Harden  5.944705\n",
       "4        Russell Westbrook  5.727851\n",
       "2            Stephen Curry  4.634020\n",
       "0             Kevin Durant  4.541718\n",
       "14        DeMarcus Cousins  4.537194\n",
       "9             LeBron James  4.444879\n",
       "20               John Wall  4.430092\n",
       "8            Isaiah Thomas  4.419591\n",
       "6    Giannis Antetokounmpo  4.344743\n",
       "3            Anthony Davis  4.219548\n",
       "10              Kyle Lowry  4.214816\n",
       "5            Kawhi Leonard  4.173067\n",
       "32            Eric Bledsoe  4.115089\n",
       "21          Damian Lillard  3.967767\n",
       "12            Jimmy Butler  3.887852\n",
       "16            Kemba Walker  3.868522\n",
       "28             Jeff Teague  3.852910\n",
       "7       Karl-Anthony Towns  3.843155\n",
       "22            Kyrie Irving  3.831783\n",
       "13             CJ McCollum  3.768428\n",
       "19              Marc Gasol  3.762130\n",
       "33             Paul George  3.737009\n",
       "42             Brook Lopez  3.724822\n",
       "29              Chris Paul  3.691913\n",
       "31             Mike Conley  3.656830\n",
       "35         Carmelo Anthony  3.593797\n",
       "30            Lou Williams  3.572137\n",
       "47           Nicolas Batum  3.555573\n",
       "24              Kevin Love  3.553334\n",
       "18          Gordon Hayward  3.549064\n",
       "..                     ...       ...\n",
       "280           Cole Aldrich  1.461078\n",
       "385         Chinanu Onuaku  1.457253\n",
       "341            Okaro White  1.446756\n",
       "429          Daniel Ochefu  1.434554\n",
       "417            Jordan Hill  1.433222\n",
       "439         Semaj Christon  1.428717\n",
       "320              Omer Asik  1.425324\n",
       "433              CJ Wilcox  1.418759\n",
       "378          Deyonta Davis  1.413589\n",
       "384          Derrick Jones  1.410955\n",
       "370           Delon Wright  1.404750\n",
       "401       Rakeem Christmas  1.399864\n",
       "419           Damian Jones  1.388262\n",
       "425            Bryn Forbes  1.386954\n",
       "364           Jakob Poeltl  1.386680\n",
       "374           Joel Anthony  1.386125\n",
       "412          Nick Collison  1.381941\n",
       "414           Kyle Singler  1.372502\n",
       "421            Steve Novak  1.368734\n",
       "395      Stephen Zimmerman  1.344804\n",
       "315            Lavoy Allen  1.344350\n",
       "415            Ian Mahinmi  1.331911\n",
       "434        Michael Gbinije  1.318762\n",
       "392         Christian Wood  1.290884\n",
       "399   Georgios Papagiannis  1.289636\n",
       "413          Bruno Caboclo  1.284032\n",
       "406       Marshall Plumlee  1.235881\n",
       "407             Mike Tobey  1.214527\n",
       "411              RJ Hunter  1.011761\n",
       "405           Danuel House  0.960622\n",
       "\n",
       "[444 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('normalized_monster_players_with_ranks_2017.xls')\n",
    "players = all_data.Name\n",
    "X = all_data[features]\n",
    "y_pred = [model.predict(np.array(row).reshape(1, 99))[0][0] for label,row in X.iterrows()]\n",
    "pred_2017 = pd.concat([players,pd.Series(y_pred, name=\"score\")], axis=1)\n",
    "pred_2017.sort_values(by=['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    7.041866\n",
       "Name: normalized_score, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_2015 = pd.read_csv('normalized_monster_players_with_ranks_2016.xls')\n",
    "stats_2015.loc[stats_2015['Name'] == 'James Harden'].normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>8.197570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James Harden</td>\n",
       "      <td>7.588382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>5.952823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>5.872150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kawhi Leonard</td>\n",
       "      <td>5.616352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>5.592807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>5.451217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>5.415466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Draymond Green</td>\n",
       "      <td>5.274482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>5.181652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>4.925067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Paul George</td>\n",
       "      <td>4.684139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>4.638065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>4.566022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>John Wall</td>\n",
       "      <td>4.535305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Trevor Ariza</td>\n",
       "      <td>4.514659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>4.457462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gordon Hayward</td>\n",
       "      <td>4.428325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Joel Embiid</td>\n",
       "      <td>4.375791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>4.349168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>4.336570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Isaiah Thomas</td>\n",
       "      <td>4.300910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>4.262397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Nicolas Batum</td>\n",
       "      <td>4.217407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>4.212390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>4.203872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Robert Covington</td>\n",
       "      <td>4.157880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>4.120368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>4.109510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Lou Williams</td>\n",
       "      <td>4.108650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Bryn Forbes</td>\n",
       "      <td>1.568301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Georgios Papagiannis</td>\n",
       "      <td>1.560042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Robin Lopez</td>\n",
       "      <td>1.558067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Damian Jones</td>\n",
       "      <td>1.554725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>RJ Hunter</td>\n",
       "      <td>1.526550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Tim Quarterman</td>\n",
       "      <td>1.508686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Omer Asik</td>\n",
       "      <td>1.486735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Boris Diaw</td>\n",
       "      <td>1.484086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Bruno Caboclo</td>\n",
       "      <td>1.479987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>Daniel Ochefu</td>\n",
       "      <td>1.464861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>AJ Hammons</td>\n",
       "      <td>1.460684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Jose Calderon</td>\n",
       "      <td>1.445874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Jordan Hill</td>\n",
       "      <td>1.432374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Richard Jefferson</td>\n",
       "      <td>1.412458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Damjan Rudez</td>\n",
       "      <td>1.393326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Marshall Plumlee</td>\n",
       "      <td>1.365436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Ian Mahinmi</td>\n",
       "      <td>1.365421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Alan Anderson</td>\n",
       "      <td>1.320795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Danuel House</td>\n",
       "      <td>1.260826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Kyle Wiltjer</td>\n",
       "      <td>1.239954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Joel Anthony</td>\n",
       "      <td>1.206211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Udonis Haslem</td>\n",
       "      <td>1.154311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Metta World Peace</td>\n",
       "      <td>1.092720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>Nick Collison</td>\n",
       "      <td>1.088125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>James Jones</td>\n",
       "      <td>1.086017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Mike Miller</td>\n",
       "      <td>1.001961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Paul Pierce</td>\n",
       "      <td>0.985075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Steve Novak</td>\n",
       "      <td>0.966326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Bobby Brown</td>\n",
       "      <td>0.932605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>Ronnie Price</td>\n",
       "      <td>0.346900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>444 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name     score\n",
       "4        Russell Westbrook  8.197570\n",
       "1             James Harden  7.588382\n",
       "0             Kevin Durant  5.952823\n",
       "6    Giannis Antetokounmpo  5.872150\n",
       "5            Kawhi Leonard  5.616352\n",
       "3            Anthony Davis  5.592807\n",
       "2            Stephen Curry  5.451217\n",
       "9             LeBron James  5.415466\n",
       "39          Draymond Green  5.274482\n",
       "14        DeMarcus Cousins  5.181652\n",
       "12            Jimmy Butler  4.925067\n",
       "33             Paul George  4.684139\n",
       "10              Kyle Lowry  4.638065\n",
       "29              Chris Paul  4.566022\n",
       "20               John Wall  4.535305\n",
       "38            Trevor Ariza  4.514659\n",
       "32            Eric Bledsoe  4.457462\n",
       "18          Gordon Hayward  4.428325\n",
       "136            Joel Embiid  4.375791\n",
       "11             Otto Porter  4.349168\n",
       "7       Karl-Anthony Towns  4.336570\n",
       "8            Isaiah Thomas  4.300910\n",
       "40          Andre Drummond  4.262397\n",
       "47           Nicolas Batum  4.217407\n",
       "21          Damian Lillard  4.212390\n",
       "16            Kemba Walker  4.203872\n",
       "97        Robert Covington  4.157880\n",
       "22            Kyrie Irving  4.120368\n",
       "24              Kevin Love  4.109510\n",
       "30            Lou Williams  4.108650\n",
       "..                     ...       ...\n",
       "425            Bryn Forbes  1.568301\n",
       "399   Georgios Papagiannis  1.560042\n",
       "127            Robin Lopez  1.558067\n",
       "419           Damian Jones  1.554725\n",
       "411              RJ Hunter  1.526550\n",
       "366         Tim Quarterman  1.508686\n",
       "320              Omer Asik  1.486735\n",
       "344             Boris Diaw  1.484086\n",
       "413          Bruno Caboclo  1.479987\n",
       "429          Daniel Ochefu  1.464861\n",
       "418             AJ Hammons  1.460684\n",
       "356          Jose Calderon  1.445874\n",
       "417            Jordan Hill  1.432374\n",
       "316      Richard Jefferson  1.412458\n",
       "363           Damjan Rudez  1.393326\n",
       "406       Marshall Plumlee  1.365436\n",
       "415            Ian Mahinmi  1.365421\n",
       "416          Alan Anderson  1.320795\n",
       "405           Danuel House  1.260826\n",
       "422           Kyle Wiltjer  1.239954\n",
       "374           Joel Anthony  1.206211\n",
       "402          Udonis Haslem  1.154311\n",
       "441      Metta World Peace  1.092720\n",
       "412          Nick Collison  1.088125\n",
       "299            James Jones  1.086017\n",
       "389            Mike Miller  1.001961\n",
       "400            Paul Pierce  0.985075\n",
       "421            Steve Novak  0.966326\n",
       "438            Bobby Brown  0.932605\n",
       "393           Ronnie Price  0.346900\n",
       "\n",
       "[444 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('normalized_monster_players_with_ranks_2017.xls')\n",
    "players = all_data.Name\n",
    "X = all_data[features]\n",
    "y_pred = [lr.predict([row])[0] for label,row in X.iterrows()]\n",
    "pred_2017 = pd.concat([players,pd.Series(y_pred, name=\"score\")], axis=1)\n",
    "pred_2017.sort_values(by=['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.read_csv('normalized_monster_players_with_ranks_2016.xls')\n",
    "t.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and calculate mean absolute error on data from 2005 to 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/scipy/linalg/basic.py:884: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.89489443047647532"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "player_stats_by_year = []\n",
    "for year in range(2005, 2017):\n",
    "    if(year != 2016):\n",
    "        thisYear = pd.read_csv('player_stats_'+str(year)+\".csv\")\n",
    "        nextYear = pd.read_csv('player_stats_'+str(year+1)+\".csv\")\n",
    "        scores_next_year = nextYear[['PLAYER', 'scores_Normalized']]\n",
    "        renamed_scores = scores_next_year.rename(index=str, columns={\"scores_Normalized\": \"y\"})\n",
    "        merged = pd.merge(thisYear, renamed_scores, on='PLAYER')\n",
    "        player_stats_by_year.append(merged)\n",
    "\n",
    "all_player_data = pd.concat(player_stats_by_year)\n",
    "lr = LinearRegression(n_jobs=-1)\n",
    "X = all_player_data.iloc[:,2:16]\n",
    "y = all_player_data.iloc[:,31]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = [lr.predict([row]) for label,row in X_test.iterrows()]\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on 2017 to predict for 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Russell Westbrook, PG</td>\n",
       "      <td>10.510057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>James Harden, SG</td>\n",
       "      <td>9.991176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Anthony Davis, PF</td>\n",
       "      <td>9.501400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>DeMarcus Cousins, PF</td>\n",
       "      <td>9.441470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Giannis Antetokounmpo, SF</td>\n",
       "      <td>9.104813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>LeBron James, SF</td>\n",
       "      <td>8.709306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>Karl-Anthony Towns, C</td>\n",
       "      <td>8.593087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>John Wall, PG</td>\n",
       "      <td>8.562143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Andre Drummond, C</td>\n",
       "      <td>8.450731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Kevin Durant, SF</td>\n",
       "      <td>8.267729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Hassan Whiteside, C</td>\n",
       "      <td>8.168664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Joel Embiid, C</td>\n",
       "      <td>7.851382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Draymond Green, PF</td>\n",
       "      <td>7.839508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>Rudy Gobert, C</td>\n",
       "      <td>7.836027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Jimmy Butler, SF</td>\n",
       "      <td>7.693898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Kawhi Leonard, SF</td>\n",
       "      <td>7.602220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Dwight Howard, C</td>\n",
       "      <td>7.567852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Stephen Curry, PG</td>\n",
       "      <td>7.561736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>DeAndre Jordan, C</td>\n",
       "      <td>7.554438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Chris Paul, PG</td>\n",
       "      <td>7.549337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Blake Griffin, PF</td>\n",
       "      <td>7.387345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Kyle Lowry, PG</td>\n",
       "      <td>7.380492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Eric Bledsoe, PG</td>\n",
       "      <td>7.326934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Paul Millsap, PF</td>\n",
       "      <td>7.252427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Kevin Love, PF</td>\n",
       "      <td>7.232065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Marc Gasol, C</td>\n",
       "      <td>7.113744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>DeMar DeRozan, SG</td>\n",
       "      <td>7.102764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Paul George, SF</td>\n",
       "      <td>7.093103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Nikola Jokic, PF</td>\n",
       "      <td>7.087862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isaiah Thomas, PG</td>\n",
       "      <td>7.049001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Georges Niang, SF</td>\n",
       "      <td>2.133408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Bruno Caboclo, SF</td>\n",
       "      <td>2.126135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Tim Quarterman, SG</td>\n",
       "      <td>2.122545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Briante Weber, PG</td>\n",
       "      <td>2.121816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Lamar Patterson, SG</td>\n",
       "      <td>2.112489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Demetrius Jackson, PG</td>\n",
       "      <td>2.096430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Diamond Stone, C</td>\n",
       "      <td>2.085842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Bryn Forbes, SG</td>\n",
       "      <td>2.068458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Johnny O'Bryant III, PF</td>\n",
       "      <td>2.051244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Quincy Acy, SF†</td>\n",
       "      <td>2.049535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>Joel Bolomboy, PF</td>\n",
       "      <td>2.039253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Henry Ellenson, PF</td>\n",
       "      <td>2.015707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Archie Goodwin, SG</td>\n",
       "      <td>2.011046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Treveon Graham, SG</td>\n",
       "      <td>2.009979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Ronnie Price, PG</td>\n",
       "      <td>2.007542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>CJ Wilcox, SG</td>\n",
       "      <td>1.999729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Arinze Onuaku, PF</td>\n",
       "      <td>1.998633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Kyle Wiltjer, F</td>\n",
       "      <td>1.961523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Bobby Brown, PG</td>\n",
       "      <td>1.946440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>John Lucas III, PG</td>\n",
       "      <td>1.911458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Walter Tavares, C</td>\n",
       "      <td>1.855377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Aaron Harrison, SG</td>\n",
       "      <td>1.832220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Derrick Jones Jr., SF</td>\n",
       "      <td>1.824250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>John Jenkins, SG</td>\n",
       "      <td>1.802794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Michael Gbinije, SG</td>\n",
       "      <td>1.801685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Gary Neal, PG</td>\n",
       "      <td>1.779371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Steve Novak, SF</td>\n",
       "      <td>1.768297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Georgios Papagiannis, C</td>\n",
       "      <td>1.762253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>Danuel House Jr., PF</td>\n",
       "      <td>1.747013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>R.J. Hunter, SG</td>\n",
       "      <td>1.636781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>471 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        PLAYER      score\n",
       "426      Russell Westbrook, PG  10.510057\n",
       "249           James Harden, SG   9.991176\n",
       "280          Anthony Davis, PF   9.501400\n",
       "139       DeMarcus Cousins, PF   9.441470\n",
       "216  Giannis Antetokounmpo, SF   9.104813\n",
       "170           LeBron James, SF   8.709306\n",
       "411      Karl-Anthony Towns, C   8.593087\n",
       "379              John Wall, PG   8.562143\n",
       "188          Andre Drummond, C   8.450731\n",
       "78            Kevin Durant, SF   8.267729\n",
       "349        Hassan Whiteside, C   8.168664\n",
       "48              Joel Embiid, C   7.851382\n",
       "81          Draymond Green, PF   7.839508\n",
       "459             Rudy Gobert, C   7.836027\n",
       "155           Jimmy Butler, SF   7.693898\n",
       "298          Kawhi Leonard, SF   7.602220\n",
       "316           Dwight Howard, C   7.567852\n",
       "79           Stephen Curry, PG   7.561736\n",
       "98           DeAndre Jordan, C   7.554438\n",
       "95              Chris Paul, PG   7.549337\n",
       "94           Blake Griffin, PF   7.387345\n",
       "65              Kyle Lowry, PG   7.380492\n",
       "123           Eric Bledsoe, PG   7.326934\n",
       "314           Paul Millsap, PF   7.252427\n",
       "172             Kevin Love, PF   7.232065\n",
       "264              Marc Gasol, C   7.113744\n",
       "64           DeMar DeRozan, SG   7.102764\n",
       "201            Paul George, SF   7.093103\n",
       "395           Nikola Jokic, PF   7.087862\n",
       "0            Isaiah Thomas, PG   7.049001\n",
       "..                         ...        ...\n",
       "215          Georges Niang, SF   2.133408\n",
       "77           Bruno Caboclo, SF   2.126135\n",
       "455         Tim Quarterman, SG   2.122545\n",
       "91           Briante Weber, PG   2.121816\n",
       "329        Lamar Patterson, SG   2.112489\n",
       "12       Demetrius Jackson, PG   2.096430\n",
       "107           Diamond Stone, C   2.085842\n",
       "313            Bryn Forbes, SG   2.068458\n",
       "406    Johnny O'Bryant III, PF   2.051244\n",
       "246            Quincy Acy, SF†   2.049535\n",
       "470          Joel Bolomboy, PF   2.039253\n",
       "199         Henry Ellenson, PF   2.015707\n",
       "292         Archie Goodwin, SG   2.011046\n",
       "345         Treveon Graham, SG   2.009979\n",
       "137           Ronnie Price, PG   2.007542\n",
       "377              CJ Wilcox, SG   1.999729\n",
       "378          Arinze Onuaku, PF   1.998633\n",
       "263            Kyle Wiltjer, F   1.961523\n",
       "262            Bobby Brown, PG   1.946440\n",
       "425         John Lucas III, PG   1.911458\n",
       "330          Walter Tavares, C   1.855377\n",
       "347         Aaron Harrison, SG   1.832220\n",
       "138      Derrick Jones Jr., SF   1.824250\n",
       "136           John Jenkins, SG   1.802794\n",
       "200        Michael Gbinije, SG   1.801685\n",
       "328              Gary Neal, PG   1.779371\n",
       "230            Steve Novak, SF   1.768297\n",
       "154    Georgios Papagiannis, C   1.762253\n",
       "393       Danuel House Jr., PF   1.747013\n",
       "169            R.J. Hunter, SG   1.636781\n",
       "\n",
       "[471 rows x 2 columns]"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('player_stats_2017')\n",
    "X = pd.read_csv('player_stats_2017').iloc[:,2:16]\n",
    "players = all_data.PLAYER\n",
    "y_pred = [lr.predict([row])[0] for label,row in X.iterrows()]\n",
    "pred_2017 = pd.concat([players,pd.Series(y_pred, name=\"score\")], axis=1)\n",
    "pred_2017.sort_values(by=['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2003,\n",
       " 2004,\n",
       " 2005,\n",
       " 2006,\n",
       " 2007,\n",
       " 2008,\n",
       " 2009,\n",
       " 2010,\n",
       " 2011,\n",
       " 2012,\n",
       " 2013,\n",
       " 2014,\n",
       " 2015,\n",
       " 2016]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(2003, 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
