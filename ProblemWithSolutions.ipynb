{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Problem: construct the best team from a list of available players. Best team is defined as the team that wins the most categories. Best team wins and all others lose (edit: make this function take the payout fractions as a parameter so it can adapt to different game types)\n",
    "\n",
    "Environment:\n",
    "(1) Player: a player represents an nba player with some total stats<br>\n",
    "(2) Team: a team has a list of current players and has a function for selecting another player\n",
    "(3) Scoring: \n",
    "    Idea 1 (Balanced): Each team competes over n categories. Teams are rated 1 - m representing who a sorted list of teams with lowest to highest scores in that category - m is the number of teams in the league. Score per team is = sum of individual score for each category. Teams are ranked at the end from highest to lowest score. Highest team wins. Downside: doesn't capture variance and distance between teams in individual categories. Doesn't capture winner takes all nature of problem.\n",
    "    Idea 2 (Extreme) : Each team competes over n categories. Best team gets a 1 for that category, all others get 0s. Score per team is = sum of individual score for each category. Teams are ranked at the end from highest to lowest score. Highest team wins.\n",
    "    Idea 3 (Distance): Each team competes over n categories. Teams get scored by calculating the zscore for each team to capture the size of the \"win\". An entire teams score is the sum of zscores. Or could take the zscore of the zscores for truly meta.\n",
    "\n",
    "Solutions:\n",
    "(1) Score players. Draft top remaining score.\n",
    "(2) Constraint solver: Run a search algo that computes every possible team and competitor team with the remaining players. Scores teams. Ranks teams. Takes player that produces the highest team score. Downside: going to take a long time to run. Needs to be able to run within 150s.\n",
    "(3) Monte carlo the problem. Predict performance for 2017. Run random simulations. If team wins, all players on winning team +1. Take make player with some random selection for exploration.\n",
    "(4) More sophistacted reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Player(object):\n",
    "    def __init__(self, name, stats):\n",
    "        self.name = name\n",
    "        self.stats = stats\n",
    "    \n",
    "class Stats(object):\n",
    "    def __init__(self, points, assists, rebounds):\n",
    "        self.points = points\n",
    "        self.assists = assists\n",
    "    #self.steals = 0\n",
    "    #self.tos = 0\n",
    "        self.rebounds = rebounds\n",
    "    #self.fgp = 0\n",
    "    #self.ftm = 0\n",
    "    #self.tpm = 0\n",
    "    #self.blocks = 0\n",
    "    #self.ftp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    \n",
    "    __metaclass__ = ABCMeta\n",
    "    \n",
    "    @abstractmethod\n",
    "    def action(self, environment):\n",
    "        pass\n",
    "\n",
    "class RandomAgent(Agent):\n",
    "    def __init__(self, players = []):\n",
    "        self.players = players\n",
    "        \n",
    "    def action(self, environment):\n",
    "        envPlayers = environment.players\n",
    "        selected = envPlayers.pop(random.randint(0,len(envPlayers)-1))\n",
    "        self.players.append(selected)\n",
    "        return Environment(players = envPlayers, agents = environment.agents)\n",
    "    \n",
    "class MaxPointsAgent(Agent):\n",
    "    def __init__(self, players = []):\n",
    "        self.players = players\n",
    "        \n",
    "    def action(self, environment):\n",
    "        envPlayers = environment.players\n",
    "        points_vec = [player.stats.points for player in players]\n",
    "        i = np.argmax(points_vec)\n",
    "        selected = envPlayers.pop(i)\n",
    "        self.players.append(selected)\n",
    "        return Environment(players = envPlayers, agents = environment.agents)\n",
    "    \n",
    "class MonteCarloAgent(Agent):\n",
    "    def __init__(self, scorer, players = []):\n",
    "        self.players = players\n",
    "        self.scorer = scorer\n",
    "    \n",
    "    def runSimulation(self, env):\n",
    "        return env\n",
    "    \n",
    "    def action(self, environment):\n",
    "        player_tracker = {}\n",
    "        newEnv = runSimulation(environment)\n",
    "        winner = scorer.score(newEnv.agents)\n",
    "        winningAgent = agents[winner]\n",
    "        for player in winningAgent.players:\n",
    "            player_tracker.update({player: int(player_tracker.get(player) or 0) + 1})\n",
    "        winningPlayer = player_tracker[np.argmax(player_tracker.values)]\n",
    "#do something once winning\n",
    "        return Environment(players = envPlayers, agents = environment.agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Scorer(object):\n",
    "    \n",
    "    __metaclass__ = ABCMeta\n",
    "    \n",
    "    @abstractmethod\n",
    "    def score(self, agents):\n",
    "        pass\n",
    "\n",
    "class SimpleSingleClassScorer(Scorer):\n",
    "    \"\"\"\n",
    "        Takes a list of agents. \n",
    "    \n",
    "        Scores by taking the argmax of a single category for those agents. \n",
    "        \n",
    "        Returns index of winner\n",
    "    \"\"\"\n",
    "    def score(self, agents):\n",
    "        list_of_points = []\n",
    "        for agent in agents:\n",
    "            players = agent.players\n",
    "            total_points = sum([player.stats.points for player in players])\n",
    "            list_of_points.append(total_points)\n",
    "        return np.argmax(list_of_points)\n",
    "    \n",
    "class SimpleMultiClassScorer(Scorer):\n",
    "    \"\"\"\n",
    "        Takes a list of agents. \n",
    "    \n",
    "        Scores by taking the argmax of a single category for those agents. \n",
    "        \n",
    "        Returns a vector in the order of the agents, representing\n",
    "        the commulative score of each agent\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.keys = ['points', 'assists']\n",
    "        \n",
    "    def score(self, agents):\n",
    "        list_of_points = []\n",
    "        list_of_assists = []\n",
    "        list_of_rebounds = []\n",
    "        score_dict = {}\n",
    "        for (i, agent) in enumerate(agents):\n",
    "            score_dict.update({i:0})\n",
    "            players = agent.players\n",
    "            total_points = sum([player.stats.points for player in players])\n",
    "            total_assists = sum([player.stats.assists for player in players])\n",
    "            total_rebounds = sum([player.stats.rebounds for player in players])\n",
    "            list_of_points.append(total_points)\n",
    "            list_of_assists.append(total_assists)\n",
    "            list_of_rebounds.append(total_rebounds)\n",
    "        index_points = np.argmax(list_of_points)\n",
    "        index_assists = np.argmax(list_of_assists)\n",
    "        index_rebounds = np.argmax(list_of_rebounds)\n",
    "        score_dict.update({index_points: int(score_dict.get(index_points) or 0) + 1})\n",
    "        score_dict.update({index_assists: int(score_dict.get(index_assists) or 0) + 1})\n",
    "        score_dict.update({index_rebounds: int(score_dict.get(index_rebounds) or 0) + 1})\n",
    "        i = np.argmax(score_dict.values())\n",
    "        return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "class Environment(object):\n",
    "    def __init__(self, players, agents):\n",
    "        self.players = players\n",
    "        self.agents = agents\n",
    "        \n",
    "class Game(object):\n",
    "    def __init__(self, players, agents, scorer):\n",
    "        self.environment = Environment(players = players, agents = agents)\n",
    "        self.agents = agents\n",
    "        self.scorer = scorer\n",
    "        \n",
    "    def run(self, numberOfDraftRounds):\n",
    "        newEnv = self.draft(self.environment, numberOfDraftRounds)\n",
    "        finalAgents = newEnv.agents\n",
    "        i = scorer.score(finalAgents)\n",
    "        return (finalAgents[i], [player.name for player in finalAgents[i].players])\n",
    "                       \n",
    "    def draft(self, env, numberOfDraftRounds):\n",
    "        newEnv = env\n",
    "        for round in range(0, numberOfDraftRounds):\n",
    "            for agent in env.agents:\n",
    "                newEnv = agent.action(newEnv)\n",
    "        return newEnv\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.RandomAgent at 0x10fe5f0d0>, ['p3'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = Player(name = 'p1', stats = Stats(points = 10, assists = 7, rebounds = 15))\n",
    "p2 = Player(name = 'p2', stats = Stats(points = 3, assists = 4, rebounds = 7))\n",
    "p3 = Player(name = 'p3', stats = Stats(points = 15, assists = 10, rebounds = 20))\n",
    "\n",
    "\n",
    "a1 = RandomAgent(players = [])\n",
    "a2 = RandomAgent(players = [])\n",
    "a3 = MaxPointsAgent(players = [])\n",
    "\n",
    "players = [p1,p2,p3]\n",
    "agents = [a1, a2, a3]\n",
    "scorer = SimpleMultiClassScorer()\n",
    "\n",
    "game = Game(players = players, agents = agents, scorer = scorer)\n",
    "\n",
    "game.run(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScoreAndPick"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ScoreAndPick: this algo applies any scoring function to a set of players, sorts the players by their score and picks the top remaining player."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ComboSolver"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ComboSolver: this algo generates every possible team from the remaining players, scores the teams, and scores the players based on the team. This algo is adaptive and doesn't rely on pretraining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MonteCarloSortAndPick"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MontoCarloSortAndPick: Run random simulations. If team wins, all players on winning team +1. Take make player with some random selection for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
