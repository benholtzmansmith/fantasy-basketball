{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Problem: construct the best team from a list of available players. Best team is defined as the team that wins the most categories. Best team wins and all others lose (edit: make this function take the payout fractions as a parameter so it can adapt to different game types)\n",
    "\n",
    "Environment:\n",
    "(1) Player: a player represents an nba player with some total stats<br>\n",
    "(2) Team: a team has a list of current players and has a function for selecting another player\n",
    "(3) Scoring: \n",
    "    Idea 1 (Balanced): Each team competes over n categories. Teams are rated 1 - m representing who a sorted list of teams with lowest to highest scores in that category - m is the number of teams in the league. Score per team is = sum of individual score for each category. Teams are ranked at the end from highest to lowest score. Highest team wins. Downside: doesn't capture variance and distance between teams in individual categories. Doesn't capture winner takes all nature of problem.\n",
    "    Idea 2 (Extreme) : Each team competes over n categories. Best team gets a 1 for that category, all others get 0s. Score per team is = sum of individual score for each category. Teams are ranked at the end from highest to lowest score. Highest team wins.\n",
    "    Idea 3 (Distance): Each team competes over n categories. Teams get scored by calculating the zscore for each team to capture the size of the \"win\". An entire teams score is the sum of zscores. Or could take the zscore of the zscores for truly meta.\n",
    "\n",
    "Solutions:\n",
    "(1) Score players. Draft top remaining score.\n",
    "(2) Constraint solver: Run a search algo that computes every possible team and competitor team with the remaining players. Scores teams. Ranks teams. Takes player that produces the highest team score. Downside: going to take a long time to run. Needs to be able to run within 150s.\n",
    "(3) Monte carlo the problem. Predict performance for 2017. Run random simulations. If team wins, all players on winning team +1. Take make player with some random selection for exploration.\n",
    "(4) More sophistacted reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Player(object):\n",
    "    def __init__(self, name, stats):\n",
    "        self.name = name\n",
    "        self.stats = stats\n",
    "    \n",
    "class Stats(object):\n",
    "    def __init__(self, points, assists):\n",
    "        self.points = points\n",
    "        self.assists = assists\n",
    "    #self.steals = 0\n",
    "    #self.tos = 0\n",
    "    #self.rebounds = 0\n",
    "    #self.fgp = 0\n",
    "    #self.ftm = 0\n",
    "    #self.tpm = 0\n",
    "    #self.blocks = 0\n",
    "    #self.ftp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    \n",
    "    __metaclass__ = ABCMeta\n",
    "    \n",
    "    @abstractmethod\n",
    "    def action(self, environment):\n",
    "        pass\n",
    "\n",
    "class RandomAgent(Agent):\n",
    "    def __init__(self, players = []):\n",
    "        self.players = players\n",
    "        \n",
    "    def action(self, environment):\n",
    "        envPlayers = environment.players\n",
    "        selected = envPlayers.pop(random.randint(0,len(envPlayers)-1))\n",
    "        self.players.append(selected)\n",
    "        return Environment(players = envPlayers)\n",
    "    \n",
    "class MaxPointsAgent(Agent):\n",
    "    def __init__(self, players = []):\n",
    "        self.players = players\n",
    "        \n",
    "    def action(self, environment):\n",
    "        envPlayers = environment.players\n",
    "        points_vec = [player.points for player in players]\n",
    "        i = np.argmax(points_vec)\n",
    "        selected = envPlayers.pop(i)\n",
    "        self.players.append(selected)\n",
    "        return Environment(players = envPlayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Scorer(object):\n",
    "    \n",
    "    __metaclass__ = ABCMeta\n",
    "    \n",
    "    @abstractmethod\n",
    "    def score(self, agents):\n",
    "        pass\n",
    "\n",
    "class SimpleSingleClassScorer(Scorer):\n",
    "    \"\"\"\n",
    "        Takes a list of agents. \n",
    "    \n",
    "        Scores by taking the argmax of a single category for those agents. \n",
    "        \n",
    "        Returns index of winner\n",
    "    \"\"\"\n",
    "    def score(self, agents):\n",
    "        list_of_points = []\n",
    "        for agent in agents:\n",
    "            players = agent.players\n",
    "            total_points = sum([player.stats.points for player in players])\n",
    "            list_of_points.append(total_points)\n",
    "        return np.argmax(list_of_points)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "class Environment(object):\n",
    "    def __init__(self, players):\n",
    "        self.players = players\n",
    "        \n",
    "class Game(object):\n",
    "    def __init__(self, players, agents, scorer):\n",
    "        self.environment = Environment(players = players)\n",
    "        self.agents = agents\n",
    "        self.scorer = scorer\n",
    "        \n",
    "    def run(self):\n",
    "        (env, agents) = self.foldAgents(self.agents, self.environment, [])\n",
    "        return scorer.score(agents)\n",
    "        \n",
    "    def foldAgents(self, agents, env, newAgents = []):\n",
    "        if(len(agents) == 0): \n",
    "            return (env, newAgents)\n",
    "        else:\n",
    "            selected = agents.pop()\n",
    "            newEnv = selected.action(env)\n",
    "            newAgents.append(selected)\n",
    "            return self.foldAgents(agents, newEnv, newAgents)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Player' object has no attribute 'points'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-283c1edfd19d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-178-7c4602b77eae>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfoldAgents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-178-7c4602b77eae>\u001b[0m in \u001b[0;36mfoldAgents\u001b[0;34m(self, agents, env, newAgents)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mselected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mnewEnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mnewAgents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfoldAgents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewAgents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-176-0f591faeb0ad>\u001b[0m in \u001b[0;36maction\u001b[0;34m(self, environment)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0menvPlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mpoints_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mplayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mselected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvPlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Player' object has no attribute 'points'"
     ]
    }
   ],
   "source": [
    "p1 = Player(name = 'ben', stats = Stats(points = 10))\n",
    "p2 = Player(name = 'cat', stats = Stats(points = 3))\n",
    "p3 = Player(name = 'joel', stats = Stats(points = 15))\n",
    "\n",
    "a1 = RandomAgent(players = [])\n",
    "a2 = RandomAgent(players = [])\n",
    "a3 = MaxPointsAgent(players = [])\n",
    "\n",
    "players = [p1,p2,p3]\n",
    "agents = [a1, a2, a3]\n",
    "scorer = SimpleSingleClassScorer()\n",
    "\n",
    "game = Game(players = players, agents = agents, scorer = scorer)\n",
    "\n",
    "print(game.run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScoreAndPick"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ScoreAndPick: this algo applies any scoring function to a set of players, sorts the players by their score and picks the top remaining player."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ComboSolver"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ComboSolver: this algo generates every possible team from the remaining players, scores the teams, and scores the players based on the team. This algo is adaptive and doesn't rely on pretraining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MonteCarloSortAndPick"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MontoCarloSortAndPick: Run random simulations. If team wins, all players on winning team +1. Take make player with some random selection for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
